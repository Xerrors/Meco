---
title: 近期论文小结
date: 2021-08-11 21:57:05
permalink: /2021-08-11-week-post/
cover: https://xerrors.oss-cn-shanghai.aliyuncs.com/imgs/20210430165756-image.png
tags: 
- 周报
categories: 周报
abstract: 这周主要是看的关系提取的论文，主要包括多模态预训练方法的ViLBERT、UNIMO；利用对比学习的实体和关系理解；
---
## 1. 多模态预训练方法

### ViLBERT

这个了解不多，首先是看到了这个论文：面向视觉基础进行预训练！（第一次看到这么调皮的标题）[[1908.02265] ViLBERT: Pretraining Task-Agnostic Visiolinguistic Representations for Vision-and-Language Tasks (arxiv.org)](https://arxiv.org/abs/1908.02265)

![ViLBERT](https://xerrors.oss-cn-shanghai.aliyuncs.com/imgs/20210811220542.png)

这里是解读文章：[BERT新转变：面向视觉基础进行预训练！ - 知乎 (zhihu.com)](https://zhuanlan.zhihu.com/p/101511981)，很不错，原文实在是晦涩难懂！

![](https://xerrors.oss-cn-shanghai.aliyuncs.com/imgs/20210811220755.png)

![](https://xerrors.oss-cn-shanghai.aliyuncs.com/imgs/20210811220822.png)

![](https://xerrors.oss-cn-shanghai.aliyuncs.com/imgs/20210811220842.png)

### UNIMO

解读文章：[机器之心](https://mp.weixin.qq.com/s/CUR57R-4xXHpVLFCJTG55w)，原谅我看不懂原文！

![](https://xerrors.oss-cn-shanghai.aliyuncs.com/imgs/20210811221154.png)

> **百度提出面向异构模态数据的统一预训练方法 UNIMO**，在具体训练过程中，文本、图像和图文对**三种模态数据随机混合**在一起，其中图像被转换为目标（object）序列，文本被转换为词（token）序列，图文对被转换为目标序列和词序列的拼接。
>
> UNIMO 对三种类型数据进行统一处理，在目标序列或者词序列上基于掩码预测进行**自监督学习**，并且基于图文对数据进行**跨模态对比学习**，从而实现图像与文本的统一表示学习。进一步的，这种联合学习方法也让文本知识和视觉知识互相增强，从而有效提升文本语义表示和视觉语义表示的能力。

![图片](https://xerrors.oss-cn-shanghai.aliyuncs.com/imgs/20210811222953-_20210811222737jpg)

> 异构模态的统一预训练最大的挑战是如何跨越不同模态间的语义鸿沟从而实现语义表示的统一。如下图所示，UNIMO 提出了创新的**跨模态对比学习**方法，同时引入相关联的图文对数据、文本数据和图像数据进行**联合对比学习**。具体地，UNIMO 通过文本改写的方式，对图文对进行数据增广，获得大量的正例和强负例图文对数据。同时为了更好的利用文本和图像数据，UNIMO 通过文本与图像检索，获得相关的图像和文本作为正例。这样利用扩充后的多种类型的正例以及高质量强负例，**UNIMO 在统一的语义空间上进行联想对比，从而能够学习到精确对齐的跨模态语义表示**。注：玄学！

![图片](https://xerrors.oss-cn-shanghai.aliyuncs.com/imgs/20210811223408-_20210811222745jpg)

下面一起来看看实验是怎么做的，反正就是很多很多数据。

> 在实验方面，UNIMO 使用了大量的文本、图像和图文数据进行联合学习，同时在各种单一模态和跨模态下游任务上进行验证。预训练数据部分，**文本语料**包括 Wikipedia、BookCorpus、OpenWebText 等共 54G 语料；**图像数据**是从互联网爬取的 170 万张图像；而**图文对数据**则包括 COCO Caption、Visual Genome、Conceptual Caption、SBU Caption。
>
> 下游任务既包括图文搜索、视觉问答、图描述生成、视觉推断等跨模态任务，也包括文本分类、阅读理解、文本摘要、问题生成等各种文本任务。模型上，Base 基于 12 层的 Transformer，而 Large 使用 24 层。

看也看不懂，只能喊666了

## 2. 利用对比学习的实体和关系理解

论文在此：[[2012.15022] ERICA: Improving Entity and Relation Understanding for Pre-trained Language Models via Contrastive Learning (arxiv.org)](https://arxiv.org/abs/2012.15022)

这篇文章所想要解决的痛点就是：传统的预训练目标没有明确地对文本中的关系事实进行建模，而这些对文本理解至关重要。

为了解决这个问题，定义了两个**新的预训练任务**来更好地理解实体和关系。

1. 实体辨别任务（ED），区分哪个尾部实体可以由给定的头部实体和关系推断出来；
2. 关系辨别任务（RD），区分两个关系在语义上是否接近，这涉及复杂的关系推理；

那么对于这两个新的任务，是不是就要有新的数据集啊，那么很抱歉并没有，所以想要使用对比学习的方法来制造负样本来完成训练。具体而言：

### Entity Discrimination Task

如图所示，对于数据集（远程监督得到的）中实体关系数据，目前已知 $(d,r,e_1,e_2)$，然后把 $(d,r,e_1)$ 输入到模型里面，让模型猜，模型就会在这个文档 $d$ 中所有出现的实体中猜，如果猜对了就加分，猜错了就减分。那么$e_1$就是正样本，其余实体都是负样本。

![图片](https://xerrors.oss-cn-shanghai.aliyuncs.com/imgs/20210815151835-imagepng)

写成数学公式就是：

$$
\mathcal{L}_{\mathrm{ED}}=-\sum_{t_{j k} \in \mathcal{T}^{+}} \log \frac{\exp \left(\cos \left(\mathbf{e}_{ j}, \mathbf{e}_{ k}\right) / \tau\right)}{\sum_{l=1, l \neq j}^{\left|\mathcal{E}\right|} \exp \left(\cos \left(\mathbf{e}_{ j}, \mathbf{e}_{ l}\right) / \tau\right)}

$$

具体的每个字母的含义是什么，就需要仔细看论文了。

### Relation Discrimination Task

对于这个任务，也是使用了对比学习。首先需要注意的是，这里的关系的表示是利用实体拼接得来的，实体的编码表示是使用 mean pooling 得到的；这里的计算方法是一样的，对于相同的关系我就加分，不同的关系我就减分，这里的关系来源可以是全部来自句内关系，也可以来自跨句关系。所以就有了这个看不懂的图和看不懂的公式了。

![图片](https://xerrors.oss-cn-shanghai.aliyuncs.com/imgs/20210815152940-imagepng)

$$
\begin{aligned}
\mathcal{L}_{\mathrm{RD}}^{\mathcal{T}_{1}, \mathcal{T}_{2}} &=-\sum_{t_{A} \in \mathcal{T}_{1}, t_{B} \in \mathcal{T}_{2}} \log \frac{\exp \left(\cos \left(\mathbf{r}_{t_{A}}, \mathbf{r}_{t_{B}}\right) / \tau\right)}{\mathcal{Z}} \\
\mathcal{Z} &=\sum_{t_{C} \in \mathcal{T} /\left\{t_{A}\right\}}^{N} \exp \left(\cos \left(\mathbf{r}_{t_{A}}, \mathbf{r}_{t_{C}}\right) / \tau\right) \\
\mathcal{L}_{\mathrm{RD}} &=\mathcal{L}_{\mathrm{RD}}^{\mathcal{T}_{s}^{+}, \mathcal{T}_{s}^{+}}+\mathcal{L}_{\mathrm{RD}}^{\mathcal{T}_{s}^{+}, \mathcal{T}_{c}^{+}}+\mathcal{L}_{\mathrm{RD}}^{\mathcal{T}_{c}^{+}, \mathcal{T}_{s}^{+}}+\mathcal{L}_{\mathrm{RD}}^{\mathcal{T}_{c}^{+}, \mathcal{T}_{c}^{+}}
\end{aligned}

$$

这里多提一句，这个 $\mathcal{Z}$ 所表示的其实就是哪些不同关系的得分。

### 总结

最后呢，还使用了一个不知道是什么玩意的损失函数，这个下面这个样子，叫做：

> 为了避免对一般语言的灾难性遗忘理解能力，我们在训练掩盖的语言建模任务($\mathcal{L}_{\mathrm{MLM}}$)，同时训练ED和RD 任务。（听着就像是一般的 mask 训练）

$$
\mathcal{L}=\mathcal{L}_{\mathrm{ED}}+\mathcal{L}_{\mathrm{RD}}+\mathcal{L}_{\mathrm{MLM}}

$$

从整个论文读下来，就感觉他的侧重点其实是长文本或者文档级的语义理解，然后恰好使用了一个 mean pooling 的方法使得整体在小样本上的表现更好。跟其他预训练模型一样，关系往往是预先制定好的关系，再然后就去进行实体和关系的分类，但是实际上的任务可能更加复杂，所以在下游任务的微调应用中，并没有很好的改善这一情况。

## 3. 实体关系提取

这是一个全新的任务，之后也会进行详细的梳理，这里只是现将最近的论文的阅读给整理出来。

### 基于Pipeline的PURE

论文在此：[[2010.12812] A Frustratingly Easy Approach for Entity and Relation Extraction (arxiv.org)](https://arxiv.org/abs/2010.12812)

解读在此：[陈丹琦“简单到令人沮丧”的屠榜之作：关系抽取新SOTA！](https://mp.weixin.qq.com/s/xwljKL3FjY-Nw-Zll4x3pQ)

**动机**：目前关于实体关系提取，多数都是采用的联合模型的方法；但是作者任务，对于实体识别和关系提取这两个任务而言，他们的上下文特征肯定是不一样的，如果通过简单的共享参数，一定会对模型的训练产生弊端的。但是另一方面，实体的文本、边界和类型信息也已经被证实对关系提取任务有帮助。

> 长期以来，人们一直认为联合模型可以更好地捕捉实体和关系之间的相互作用，并有助于缓解错误传播问题。

所以就提出来了一个新的策略（似乎并不能够叫做模型）

目前 Pipeline 所存在的问题是：

1. pipeline方式存在误差积累吗，还会增加计算复杂度（实体冗余计算）
2. pipeline方式存在交互缺失，忽略实体和关系两个任务之间的内在联系

![图片](https://xerrors.oss-cn-shanghai.aliyuncs.com/imgs/20210816161215-imagepng)

对于实体模型，似乎并没有什么改进策略，输入是文本，从所有 span（段）中找到可能的实体；主要是关系提取模块，这里的输入融合了前面得到的实体信息，包括文本标签和类型标签，嵌入在每个实体的前后；但是这样会导致计算开销太大，所以后面就使用了一个新的加速的方法，后面单独记录。

> 之前也有学者重新使用跨度表征 $h_i$ 和 $h_j$ 来预测 $s_i$ 和 $s_j$ 之间的关系，作者假设这些表征只捕捉到每个单独实体周围的上下文信息，可能无法捕捉到一对 spans 之间的依赖关系。我们还认为，在不同的 spans 对之间共享上下文表述可能是次优的。

所以，作者的关系模型独立地处理每一对 spans，并在输入层插入类型标记，以突出主语和宾语及其类型。

![图片](https://xerrors.oss-cn-shanghai.aliyuncs.com/imgs/20210816163957-imagepng)

**在跨句上下文处理**上，使用了一个窗口大小为 W 的机制，具体来说，给定一个有 n 个单词的输入句子，分别从左侧语境和右侧语境中增加 (W-n)/2 个单词。（我不理解为什么 W 的增加会导致关系提取效果变差，原论文只字未提，难道是因为过大的无关文本对关系判断产生了干扰？）

![图片](https://xerrors.oss-cn-shanghai.aliyuncs.com/imgs/20210816163606-imagepng)

**加速方面**；作者提出，这个方法的主要缺点就是没对实体都要运行一次关系模型，参考图中（b）的这个句子需要执行两次，因为每次的输入并不一样。具体而言就是将实体的文本和实体的类型标签共享相同的位置编码，之后将编码后的标签标记拼接到句子的最后面；同时在注意力层加上约束（这里的约束是指类似于 mask 的东西吗？），使得文本标记只能关注到文本标记，类型标记可以关注到同批次的四个标签和前面的文本标记（个人理解）。

**结论就是**：作者笃定，对于实体关系提取任务里面，简单的共享编码器会导致效果变得更差（起码对于这个模型而言），此外，实体信息可以明显的提升关系提取的效果，但是关系提取的结果并没有对实体提取有明显的帮助。

那么问题来了：

1. 联合模型为什么能够取得更好的效果呢？
2. Pipeline 的反向传播一样也是从后往前进行传播的，具体是怎么训练的？
3. 为什么 W 的增加会导致关系提取效果变差？

## 参考资料

太多了
