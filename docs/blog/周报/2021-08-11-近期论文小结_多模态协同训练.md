---
title: 近期论文小结（多模态协同训练）
date: 2021-08-11 21:57:05
permalink: /2021-08-11-week-post/
cover: https://xerrors.oss-cn-shanghai.aliyuncs.com/imgs/20210430165756-image.png
tags: 
- 周报
categories: 周报
---
## 1. 多模态预训练方法

### ViLBERT

这个了解不多，首先是看到了这个论文：面向视觉基础进行预训练！（第一次看到这么调皮的标题）[[1908.02265] ViLBERT: Pretraining Task-Agnostic Visiolinguistic Representations for Vision-and-Language Tasks (arxiv.org)](https://arxiv.org/abs/1908.02265)

![ViLBERT](https://xerrors.oss-cn-shanghai.aliyuncs.com/imgs/20210811220542.png)

这里是解读文章：[BERT新转变：面向视觉基础进行预训练！ - 知乎 (zhihu.com)](https://zhuanlan.zhihu.com/p/101511981)，很不错，原文实在是晦涩难懂！

![](https://xerrors.oss-cn-shanghai.aliyuncs.com/imgs/20210811220755.png)

![](https://xerrors.oss-cn-shanghai.aliyuncs.com/imgs/20210811220822.png)

![](https://xerrors.oss-cn-shanghai.aliyuncs.com/imgs/20210811220842.png)

### UNIMO

解读文章：[机器之心](https://mp.weixin.qq.com/s/CUR57R-4xXHpVLFCJTG55w)，原谅我看不懂原文！

![](https://xerrors.oss-cn-shanghai.aliyuncs.com/imgs/20210811221154.png)

> **百度提出面向异构模态数据的统一预训练方法 UNIMO**，在具体训练过程中，文本、图像和图文对**三种模态数据随机混合**在一起，其中图像被转换为目标（object）序列，文本被转换为词（token）序列，图文对被转换为目标序列和词序列的拼接。
>
> UNIMO 对三种类型数据进行统一处理，在目标序列或者词序列上基于掩码预测进行**自监督学习**，并且基于图文对数据进行**跨模态对比学习**，从而实现图像与文本的统一表示学习。进一步的，这种联合学习方法也让文本知识和视觉知识互相增强，从而有效提升文本语义表示和视觉语义表示的能力。

![图片](https://xerrors.oss-cn-shanghai.aliyuncs.com/imgs/20210811222953-_20210811222737jpg)

> 异构模态的统一预训练最大的挑战是如何跨越不同模态间的语义鸿沟从而实现语义表示的统一。如下图所示，UNIMO 提出了创新的**跨模态对比学习**方法，同时引入相关联的图文对数据、文本数据和图像数据进行**联合对比学习**。具体地，UNIMO 通过文本改写的方式，对图文对进行数据增广，获得大量的正例和强负例图文对数据。同时为了更好的利用文本和图像数据，UNIMO 通过文本与图像检索，获得相关的图像和文本作为正例。这样利用扩充后的多种类型的正例以及高质量强负例，**UNIMO 在统一的语义空间上进行联想对比，从而能够学习到精确对齐的跨模态语义表示**。注：玄学！

![图片](https://xerrors.oss-cn-shanghai.aliyuncs.com/imgs/20210811223408-_20210811222745jpg)

下面一起来看看实验是怎么做的，反正就是很多很多数据。

> 在实验方面，UNIMO 使用了大量的文本、图像和图文数据进行联合学习，同时在各种单一模态和跨模态下游任务上进行验证。预训练数据部分，**文本语料**包括 Wikipedia、BookCorpus、OpenWebText 等共 54G 语料；**图像数据**是从互联网爬取的 170 万张图像；而**图文对数据**则包括 COCO Caption、Visual Genome、Conceptual Caption、SBU Caption。
>
> 下游任务既包括图文搜索、视觉问答、图描述生成、视觉推断等跨模态任务，也包括文本分类、阅读理解、文本摘要、问题生成等各种文本任务。模型上，Base 基于 12 层的 Transformer，而 Large 使用 24 层。

看也看不懂，只能喊666了

## 2. 利用对比学习的实体和关系理解

论文在此：[[2012.15022] ERICA: Improving Entity and Relation Understanding for Pre-trained Language Models via Contrastive Learning (arxiv.org)](https://arxiv.org/abs/2012.15022)

这篇文章所想要解决的痛点就是：传统的预训练目标没有明确地对文本中的关系事实进行建模，而这些对文本理解至关重要。

为了解决这个问题，定义了两个**新的预训练任务**来更好地理解实体和关系。

1. 实体辨别任务（ED），区分哪个尾部实体可以由给定的头部实体和关系推断出来；
2. 关系辨别任务（RD），区分两个关系在语义上是否接近，这涉及复杂的关系推理；

那么对于这两个新的任务，是不是就要有新的数据集啊，那么很抱歉并没有，所以想要使用对比学习的方法来制造负样本来完成训练。具体而言：

**Entity Discrimination Task**

如图所示，对于数据集（远程监督得到的）中实体关系数据，目前已知 $(d,r,e_1,e_2)$，然后把 $(d,r,e_1)$ 输入到模型里面，让模型猜，模型就会在这个文档 $d$ 中所有出现的实体中猜，如果猜对了就加分，猜错了就减分。那么$e_1$就是正样本，其余实体都是负样本。

![图片](https://xerrors.oss-cn-shanghai.aliyuncs.com/imgs/20210815151835-imagepng)

写成数学公式就是：

$$
\mathcal{L}_{\mathrm{ED}}=-\sum_{t_{j k} \in \mathcal{T}^{+}} \log \frac{\exp \left(\cos \left(\mathbf{e}_{ j}, \mathbf{e}_{ k}\right) / \tau\right)}{\sum_{l=1, l \neq j}^{\left|\mathcal{E}\right|} \exp \left(\cos \left(\mathbf{e}_{ j}, \mathbf{e}_{ l}\right) / \tau\right)}

$$

具体的每个字母的含义是什么，就需要仔细看论文了。

**Relation Discrimination Task**

对于这个任务，也是使用了对比学习。首先需要注意的是，这里的关系的表示是利用实体拼接得来的，实体的编码表示是使用 mean pooling 得到的；这里的计算方法是一样的，对于相同的关系我就加分，不同的关系我就减分，这里的关系来源可以是全部来自句内关系，也可以来自跨句关系。所以就有了这个看不懂的图和看不懂的公式了。

![图片](https://xerrors.oss-cn-shanghai.aliyuncs.com/imgs/20210815152940-imagepng)

$$
\begin{aligned}
\mathcal{L}_{\mathrm{RD}}^{\mathcal{T}_{1}, \mathcal{T}_{2}} &=-\sum_{t_{A} \in \mathcal{T}_{1}, t_{B} \in \mathcal{T}_{2}} \log \frac{\exp \left(\cos \left(\mathbf{r}_{t_{A}}, \mathbf{r}_{t_{B}}\right) / \tau\right)}{\mathcal{Z}} \\
\mathcal{Z} &=\sum_{t_{C} \in \mathcal{T} /\left\{t_{A}\right\}}^{N} \exp \left(\cos \left(\mathbf{r}_{t_{A}}, \mathbf{r}_{t_{C}}\right) / \tau\right) \\
\mathcal{L}_{\mathrm{RD}} &=\mathcal{L}_{\mathrm{RD}}^{\mathcal{T}_{s}^{+}, \mathcal{T}_{s}^{+}}+\mathcal{L}_{\mathrm{RD}}^{\mathcal{T}_{s}^{+}, \mathcal{T}_{c}^{+}}+\mathcal{L}_{\mathrm{RD}}^{\mathcal{T}_{c}^{+}, \mathcal{T}_{s}^{+}}+\mathcal{L}_{\mathrm{RD}}^{\mathcal{T}_{c}^{+}, \mathcal{T}_{c}^{+}}
\end{aligned}

$$

这里多提一句，这个 $\mathcal{Z}$ 所表示的其实就是哪些不同关系的得分。

最后呢，还使用了一个不知道是什么玩意的损失函数，这个下面这个样子，叫做：

> 为了避免对一般语言的灾难性遗忘理解能力，我们在训练掩盖的语言建模任务($\mathcal{L}_{\mathrm{MLM}}$)，同时训练ED和RD 任务。（听着就像是一般的 mask 训练）

$$
\mathcal{L}=\mathcal{L}_{\mathrm{ED}}+\mathcal{L}_{\mathrm{RD}}+\mathcal{L}_{\mathrm{MLM}}

$$


**总结**

从整个论文读下来，就感觉他的侧重点其实是长文本或者文档级的语义理解，然后恰好使用了一个 mean pooling 的方法使得整体在小样本上的表现更好。跟其他预训练模型一样，关系往往是预先制定好的关系，再然后就去进行实体和关系的分类，但是实际上的任务可能更加复杂，所以在下游任务的微调应用中，并没有很好的改善这一情况。
