---
title: 近期论文阅读笔记与小结-NLP
date: 2021-08-11 21:57:05
permalink: /2021-08-11-week-post/
cover: https://xerrors.oss-cn-shanghai.aliyuncs.com/imgs/20210430165756-image.png
tags: 
- 周报
categories: 周报
abstract: 这周主要是看的关系提取的论文，主要包括多模态预训练方法的ViLBERT、UNIMO；利用对比学习的实体和关系理解；
---
## 1. 多模态预训练方法

### ViLBERT

这个了解不多，首先是看到了这个论文：面向视觉基础进行预训练！（第一次看到这么调皮的标题）[[1908.02265] ViLBERT: Pretraining Task-Agnostic Visiolinguistic Representations for Vision-and-Language Tasks (arxiv.org)](https://arxiv.org/abs/1908.02265)

![ViLBERT](https://xerrors.oss-cn-shanghai.aliyuncs.com/imgs/20210811220542.png)

这里是解读文章：[BERT新转变：面向视觉基础进行预训练！ - 知乎 (zhihu.com)](https://zhuanlan.zhihu.com/p/101511981)，很不错，原文实在是晦涩难懂！

![](https://xerrors.oss-cn-shanghai.aliyuncs.com/imgs/20210811220755.png)

![](https://xerrors.oss-cn-shanghai.aliyuncs.com/imgs/20210811220822.png)

![](https://xerrors.oss-cn-shanghai.aliyuncs.com/imgs/20210811220842.png)

### UNIMO

解读文章：[机器之心](https://mp.weixin.qq.com/s/CUR57R-4xXHpVLFCJTG55w)，原谅我看不懂原文！

![](https://xerrors.oss-cn-shanghai.aliyuncs.com/imgs/20210811221154.png)

> **百度提出面向异构模态数据的统一预训练方法 UNIMO**，在具体训练过程中，文本、图像和图文对**三种模态数据随机混合**在一起，其中图像被转换为目标（object）序列，文本被转换为词（token）序列，图文对被转换为目标序列和词序列的拼接。
>
> UNIMO 对三种类型数据进行统一处理，在目标序列或者词序列上基于掩码预测进行**自监督学习**，并且基于图文对数据进行**跨模态对比学习**，从而实现图像与文本的统一表示学习。进一步的，这种联合学习方法也让文本知识和视觉知识互相增强，从而有效提升文本语义表示和视觉语义表示的能力。

![图片](https://xerrors.oss-cn-shanghai.aliyuncs.com/imgs/20210811222953-_20210811222737jpg)

> 异构模态的统一预训练最大的挑战是如何跨越不同模态间的语义鸿沟从而实现语义表示的统一。如下图所示，UNIMO 提出了创新的**跨模态对比学习**方法，同时引入相关联的图文对数据、文本数据和图像数据进行**联合对比学习**。具体地，UNIMO 通过文本改写的方式，对图文对进行数据增广，获得大量的正例和强负例图文对数据。同时为了更好的利用文本和图像数据，UNIMO 通过文本与图像检索，获得相关的图像和文本作为正例。这样利用扩充后的多种类型的正例以及高质量强负例，**UNIMO 在统一的语义空间上进行联想对比，从而能够学习到精确对齐的跨模态语义表示**。注：玄学！

![图片](https://xerrors.oss-cn-shanghai.aliyuncs.com/imgs/20210811223408-_20210811222745jpg)

下面一起来看看实验是怎么做的，反正就是很多很多数据。

> 在实验方面，UNIMO 使用了大量的文本、图像和图文数据进行联合学习，同时在各种单一模态和跨模态下游任务上进行验证。预训练数据部分，**文本语料**包括 Wikipedia、BookCorpus、OpenWebText 等共 54G 语料；**图像数据**是从互联网爬取的 170 万张图像；而**图文对数据**则包括 COCO Caption、Visual Genome、Conceptual Caption、SBU Caption。
>
> 下游任务既包括图文搜索、视觉问答、图描述生成、视觉推断等跨模态任务，也包括文本分类、阅读理解、文本摘要、问题生成等各种文本任务。模型上，Base 基于 12 层的 Transformer，而 Large 使用 24 层。

看也看不懂，只能喊666了

## 2. 利用对比学习的实体和关系理解

论文在此：[[2012.15022] ERICA: Improving Entity and Relation Understanding for Pre-trained Language Models via Contrastive Learning (arxiv.org)](https://arxiv.org/abs/2012.15022)

这篇文章所想要解决的痛点就是：传统的预训练目标没有明确地对文本中的关系事实进行建模，而这些对文本理解至关重要。

为了解决这个问题，定义了两个**新的预训练任务**来更好地理解实体和关系。

1. 实体辨别任务（ED），区分哪个尾部实体可以由给定的头部实体和关系推断出来；
2. 关系辨别任务（RD），区分两个关系在语义上是否接近，这涉及复杂的关系推理；

那么对于这两个新的任务，是不是就要有新的数据集啊，那么很抱歉并没有，所以想要使用对比学习的方法来制造负样本来完成训练。具体而言：

### Entity Discrimination Task

如图所示，对于数据集（远程监督得到的）中实体关系数据，目前已知 $(d,r,e_1,e_2)$，然后把 $(d,r,e_1)$ 输入到模型里面，让模型猜，模型就会在这个文档 $d$ 中所有出现的实体中猜，如果猜对了就加分，猜错了就减分。那么$e_1$就是正样本，其余实体都是负样本。

![图片](https://xerrors.oss-cn-shanghai.aliyuncs.com/imgs/20210815151835-imagepng)

写成数学公式就是：

$$
\mathcal{L}_{\mathrm{ED}}=-\sum_{t_{j k} \in \mathcal{T}^{+}} \log \frac{\exp \left(\cos \left(\mathbf{e}_{ j}, \mathbf{e}_{ k}\right) / \tau\right)}{\sum_{l=1, l \neq j}^{\left|\mathcal{E}\right|} \exp \left(\cos \left(\mathbf{e}_{ j}, \mathbf{e}_{ l}\right) / \tau\right)}

$$

具体的每个字母的含义是什么，就需要仔细看论文了。

### Relation Discrimination Task

对于这个任务，也是使用了对比学习。首先需要注意的是，这里的关系的表示是利用实体拼接得来的，实体的编码表示是使用 mean pooling 得到的；这里的计算方法是一样的，对于相同的关系我就加分，不同的关系我就减分，这里的关系来源可以是全部来自句内关系，也可以来自跨句关系。所以就有了这个看不懂的图和看不懂的公式了。

![图片](https://xerrors.oss-cn-shanghai.aliyuncs.com/imgs/20210815152940-imagepng)

$$
\begin{aligned}
\mathcal{L}_{\mathrm{RD}}^{\mathcal{T}_{1}, \mathcal{T}_{2}} &=-\sum_{t_{A} \in \mathcal{T}_{1}, t_{B} \in \mathcal{T}_{2}} \log \frac{\exp \left(\cos \left(\mathbf{r}_{t_{A}}, \mathbf{r}_{t_{B}}\right) / \tau\right)}{\mathcal{Z}} \\
\mathcal{Z} &=\sum_{t_{C} \in \mathcal{T} /\left\{t_{A}\right\}}^{N} \exp \left(\cos \left(\mathbf{r}_{t_{A}}, \mathbf{r}_{t_{C}}\right) / \tau\right) \\
\mathcal{L}_{\mathrm{RD}} &=\mathcal{L}_{\mathrm{RD}}^{\mathcal{T}_{s}^{+}, \mathcal{T}_{s}^{+}}+\mathcal{L}_{\mathrm{RD}}^{\mathcal{T}_{s}^{+}, \mathcal{T}_{c}^{+}}+\mathcal{L}_{\mathrm{RD}}^{\mathcal{T}_{c}^{+}, \mathcal{T}_{s}^{+}}+\mathcal{L}_{\mathrm{RD}}^{\mathcal{T}_{c}^{+}, \mathcal{T}_{c}^{+}}
\end{aligned}

$$

这里多提一句，这个 $\mathcal{Z}$ 所表示的其实就是哪些不同关系的得分。

### 总结

最后呢，还使用了一个不知道是什么玩意的损失函数，这个下面这个样子，叫做：

> 为了避免对一般语言的灾难性遗忘理解能力，我们在训练掩盖的语言建模任务($\mathcal{L}_{\mathrm{MLM}}$)，同时训练ED和RD 任务。（听着就像是一般的 mask 训练）

$$
\mathcal{L}=\mathcal{L}_{\mathrm{ED}}+\mathcal{L}_{\mathrm{RD}}+\mathcal{L}_{\mathrm{MLM}}

$$

从整个论文读下来，就感觉他的侧重点其实是长文本或者文档级的语义理解，然后恰好使用了一个 mean pooling 的方法使得整体在小样本上的表现更好。跟其他预训练模型一样，关系往往是预先制定好的关系，再然后就去进行实体和关系的分类，但是实际上的任务可能更加复杂，所以在下游任务的微调应用中，并没有很好的改善这一情况。

## 3. 实体关系提取

这是一个全新的任务，之后也会进行详细的梳理，这里只是现将最近的论文的阅读给整理出来。

### 基于Pipeline的PURE

论文在此：[[2010.12812] A Frustratingly Easy Approach for Entity and Relation Extraction (arxiv.org)](https://arxiv.org/abs/2010.12812)

解读在此：[陈丹琦“简单到令人沮丧”的屠榜之作：关系抽取新SOTA！](https://mp.weixin.qq.com/s/xwljKL3FjY-Nw-Zll4x3pQ)

**动机**：目前关于实体关系提取，多数都是采用的联合模型的方法；但是作者任务，对于实体识别和关系提取这两个任务而言，他们的上下文特征肯定是不一样的，如果通过简单的共享参数，一定会对模型的训练产生弊端的。但是另一方面，实体的文本、边界和类型信息也已经被证实对关系提取任务有帮助。

> 长期以来，人们一直认为联合模型可以更好地捕捉实体和关系之间的相互作用，并有助于缓解错误传播问题。

所以就提出来了一个新的策略（似乎并不能够叫做模型）

目前 Pipeline 所存在的问题是：

1. pipeline方式存在误差积累吗，还会增加计算复杂度（实体冗余计算）
2. pipeline方式存在交互缺失，忽略实体和关系两个任务之间的内在联系

![图片](https://xerrors.oss-cn-shanghai.aliyuncs.com/imgs/20210816161215-imagepng)

对于实体模型，似乎并没有什么改进策略，输入是文本，从所有 span（段）中找到可能的实体；主要是关系提取模块，这里的输入融合了前面得到的实体信息，包括文本标签和类型标签，嵌入在每个实体的前后；但是这样会导致计算开销太大，所以后面就使用了一个新的加速的方法，后面单独记录。

> 之前也有学者重新使用跨度表征 $h_i$ 和 $h_j$ 来预测 $s_i$ 和 $s_j$ 之间的关系，作者假设这些表征只捕捉到每个单独实体周围的上下文信息，可能无法捕捉到一对 spans 之间的依赖关系。我们还认为，在不同的 spans 对之间共享上下文表述可能是次优的。

所以，作者的关系模型独立地处理每一对 spans，并在输入层插入类型标记，以突出主语和宾语及其类型。

![图片](https://xerrors.oss-cn-shanghai.aliyuncs.com/imgs/20210816163957-imagepng)

**在跨句上下文处理**上，使用了一个窗口大小为 W 的机制，具体来说，给定一个有 n 个单词的输入句子，分别从左侧语境和右侧语境中增加 (W-n)/2 个单词。（我不理解为什么 W 的增加会导致关系提取效果变差，原论文只字未提，难道是因为过大的无关文本对关系判断产生了干扰？）

![图片](https://xerrors.oss-cn-shanghai.aliyuncs.com/imgs/20210816163606-imagepng)

**加速方面**；作者提出，这个方法的主要缺点就是没对实体都要运行一次关系模型，参考图中（b）的这个句子需要执行两次，因为每次的输入并不一样。具体而言就是将实体的文本和实体的类型标签共享相同的位置编码，之后将编码后的标签标记拼接到句子的最后面；同时在注意力层加上约束（这里的约束是指类似于 mask 的东西吗？），使得文本标记只能关注到文本标记，类型标记可以关注到同批次的四个标签和前面的文本标记（个人理解）。

**结论就是**：作者笃定，对于实体关系提取任务里面，简单的共享编码器会导致效果变得更差（起码对于这个模型而言），此外，实体信息可以明显的提升关系提取的效果，但是关系提取的结果并没有对实体提取有明显的帮助。

那么问题来了：

1. 联合模型为什么能够取得更好的效果呢？
2. Pipeline 的反向传播一样也是从后往前进行传播的，具体是怎么训练的？
3. 为什么 W 的增加会导致关系提取效果变差？

### 解决暴露偏差的联合提取 TPLinker

![图片](https://xerrors.oss-cn-shanghai.aliyuncs.com/imgs/20210817160640-imagepng)

题目：TPLinker: Single-stage Joint Extraction of Entities and Relations Through Token Pair Linking

论文：[2010.13415.pdf (arxiv.org)](https://arxiv.org/pdf/2010.13415.pdf)

参考：[实体关系抽取新范式！TPLinker：单阶段联合抽取，并解决暴漏偏差～ - 知乎 (zhihu.com)](https://zhuanlan.zhihu.com/p/346897151)

**更新**：

我多看了几篇文章，才发现这个方法已经这么普遍了吗？

1. [基于DGCNN和概率图的轻量级信息抽取模型 - 科学空间|Scientific Spaces (kexue.fm)- 2019](https://kexue.fm/archives/6671)

![图片](https://xerrors.oss-cn-shanghai.aliyuncs.com/imgs/20210817192436-imagepng)

2. [A Novel Cascade Binary Tagging Framework for Relational Triple Extraction (arxiv.org)- 2019](https://arxiv.org/abs/1909.03227)（文中的主要对比模型）

![图片](https://xerrors.oss-cn-shanghai.aliyuncs.com/imgs/20210817191043-imagepng)

**划重点**：TPLinker是实体关系抽取的新范式（发表时），巧妙设计了**统一的联合抽取标注框架**，可实现单阶段联合抽取、并解决暴漏偏差，同时依旧可以解决复杂的重叠关系抽取。还解决了训练过程中过于依赖 gold 的问题。

接下来就主要介绍一下这个论文的核心部分，其实也就是两个图和一个解码过程；

![图片](https://xerrors.oss-cn-shanghai.aliyuncs.com/imgs/20210817161145-imagepng)

试想一下，实体的坐标对应关系有哪些，实体头（$E_{head}$）对应实体尾（$E_{tail}$），主语头（$S_{head}$）与宾语头（$O_{head}$），主语尾（$S_{head}$）与宾语尾（$O_{head}$）；（注：其实好像两个关系就够了哈，实体头与尾，主语头与宾语头，另外一个关系是可以由前两者得到的，就是解码起来会麻烦一点，先不管这么多了）

对于一个句子而言，实体头和实体尾的标记矩阵只需要一个就够了，但是主语与宾语之间的标记矩阵就需要根据关系来确定，每个关系都需要有一个头关系对应表（SH-to-OH）与尾关系对应表（ST-to-OT）；所以对于每一个句子就需要 2*R+1 个矩阵，后来作者想了想太浪费空间了，就改成了上三角矩阵的，把原本下三角部分的值直接折叠上去（如上图右部分），用 2 来表示反的对应关系，毕竟两个实体不会同时出现互为主语与宾语的关系吧（起码在测试集上不会出现，不会出现主动关系与被动关系就是两种关系的情况）。

这里我要吐槽一下这个图画的，图中不同颜色的方块是在不同的矩阵的，针对不同的关系对应的矩阵值也是不一样的，就比如右图中蓝色的 1 跟蓝色的 2 并不在一个矩阵，所以并不是因为 1+1 所以写作 2；对了，作者后来为了计算方便就把上三角矩阵拉平，改成了一个向量（如下图）。

![图片](https://xerrors.oss-cn-shanghai.aliyuncs.com/imgs/20210817162425-imagepng)

也就是模型的输出其实就是这样一个矩阵图，估计算法看了也是一脸懵逼，所以作者还特意写了一个很长的解码算法；（我是万万没想到关系的表示可以复杂到这个成都，这都能直接拿给隔壁信息安全专业做编码解码算法了吧）

![图片](https://xerrors.oss-cn-shanghai.aliyuncs.com/imgs/20210817163058-imagepng)

看不懂，请拿走谢谢！🙄

这时候就要祭出我的 jay 大佬给的例子了：

> [JayJay - 知乎 (zhihu.com)](https://www.zhihu.com/people/lou-jie-9)
>
> TPLinker的解码过程为：
>
> 1. 解码EH-to-ET可以得到句子中所有的实体，用实体头token idx作为key，实体作为value，存入字典D中；
> 2. 对每种关系r，解码ST-to-OT得到token对存入集合E中，解码SH-to-OH得到token对并在D中关联其token idx的实体value；
> 3. 对上一步中得到的SH-to-OH token对的所有实体value对，在集合E中依次查询是否其尾token对在E中，进而可以得到三元组信息。
>
> 结合上图的具体case,我们具体描述一下解码过程：
>
> 解码EH-to-ET中得到3个实体：`{New York,New York City,De Blasio}`; 字典D为：`{New:(New York,New York City),De:(De Blasio)}`
>
> 以关系“ **mayor** ”为例,
>
> 1. 解码ST-to-OT得到集合E：`{(City,Blasio)}`;解码SH-to-OH得到`{(New,De)}`，其在字典D中可关联的subject实体集合为`{New York,New York City}`;object集合`{De Blasio}`;
> 2. 遍历上述subject集合和object集合，并在集合E中查询尾token，发现只有一个实体三元组{New York City,mayor,De Blasio}
>
> 以关系“ **born in** ”为例,
>
> 1. 解码 ST-to-OT 得到集合 E：`{(Blasio,York),(Blasio,City)}`; 解码 SH-to-OH 得到 `{(De,New)}`，其在字典D中可关联的subject实体集合为 `{De Blasio}`; object集合为`{New York,New York City}`;
> 2. 遍历上述 subject 集合和 object 集合，并在集合 E 中查询尾 token，可得到 2 个实体三元组：`{De Blasio,born in,New York}` 和 `{De Blasio,born in,New York City}`
>
> 由于关系live in与born in一样，所以我们最终可得到5个三元组：
>
> `(New York City, mayor, De Blasio), (De Blasio, born in, New York), (De Blasio, born in, New York City), (De Blasio, live in, New York), (De Blasio, live in, New York City)`
>
> 其实，只要TPLinker的解码过程，对这篇论文就会有深刻的理解了！大家一定要多看哦～

PS：这个 **HandShaking** 啥意思？？？？

PS2：文中是这么说的：据我们所知，TPLinker是**第一个单阶段联合提取模型**，可以提取各种重叠关系而不受暴露偏差的影响。

### 基于跨度的联合提取模型

![图片](https://xerrors.oss-cn-shanghai.aliyuncs.com/imgs/20210818150953-imagepng)

论文在此：[1909.07755.pdf (arxiv.org)](https://arxiv.org/pdf/1909.07755.pdf)

话不多说先看摘要：

> 我们介绍了SpERT，一个用于基于跨度的**联合实体和关系提取的注意模型**。我们的主要贡献是对 BERT 嵌入的**轻量级**推理，其特点是实体识别和过滤，以及用一个**本地化的、无标记的上下文表示**进行关系分类。该模型使用强大的**句子内负面样本**进行训练，这些样本在**单一的**BERT通道中被有效地提取。这些方面促进了对句子中**所有跨度的搜索**。在消融研究中，我们证明了预训练、强负向采样和本地化语境的好处。我们的模型在几个数据集上的实体和关系的联合提取方面比以前的工作高出2.6%的F1分数。

那么下面就针对这里说的亮点来记录一下。这里的目的就是解决实体重叠的识别问题、减少运算开销、使用BERT fine-tune。

先看模型图（这个图画的是真的粗糙啊！）

![图片](https://xerrors.oss-cn-shanghai.aliyuncs.com/imgs/20210818151504-imagepng)

**简述一下训练过程**，首先是使用 BERT 对输入的句子编码，同时还多输出了一个分类标签来表示全局语境（绿色）；然后对于**所有**可能的实体的编码进行池化操作后（红色）拼上位置编码（蓝色，**怎么得到的**）和语境标记（绿色）作为实体分类器的输入（a过程），分类器的输出是实体的类型。

之后对于所有的 span 进行过滤（b过程），比如没有识别出来的、长度超过10的，这样剩下的 span 就会少很多了，得到了实体集合；

之后在这个实体集合里面随机取两个实体，然后呢为了增加上下文信息，把这俩实体之间的句子的编码（黄色）也池化之后跟两个实体拼接一起；这就构成了关系分类器的输入了。关系分类器就根据这些信息来判断关系（c过程）。

这时候**回头看一下摘要**里面的关键词，“联合实体和关系提取的注意模型”达到了；“本地化的、无标记的上下文表示”就是指这个黄色部分的上下文了；“轻量级、单一”呢，指的就是对于每个句子，都只需要通过 BERT 一次（这也算不上优点吧），“所有跨度的搜索”是指在 a 过程中遍历了所有可能的实体并且在 b 过程筛选掉了一些不合适的跨度（span）。

最后就是**句子内负样本**了，暂时没搞明白具体是怎么训练的，强负例就是两个span之间没有任何关系

![图片](https://xerrors.oss-cn-shanghai.aliyuncs.com/imgs/20210818154454-imagepng)

附上实验结果：

![图片](https://xerrors.oss-cn-shanghai.aliyuncs.com/imgs/20210818154551-imagepng)

**实验结论**：

1. 通过对比实验发现，全局的上下文信息并没有让关系的分类更加准确，反而让效果变得更差；这表明需要将模型引向所输入句子的相关部分才能取得更好的效果（不至于被干扰）；
2. 负例样本的数量增加到一定程度之后就不会再由效果的提升了，且弱负例样本效果不好；
3. 预训练效果不错；最大池化效果要好过平均池化（为啥要用池化啊）；
4. span 过滤不仅有利于训练和评估速度，而且对SpERT中的准确定位也至关重要（这是通过实验看出来的，原理没说）。

这篇论文最让我惊讶的是还附带了**错误分析**：

![图片](https://xerrors.oss-cn-shanghai.aliyuncs.com/imgs/20210818161532-imagepng)

图中的示例分别对应了五个不同类型的错误，分别是边界错误、语义错误、无法识别隐式逻辑事实、关系预测错误、数据标注的错误。（PS：个人认为，这应该是所有的实体卦象你提取模型所要面对的问题吧）

**结论**：

> 我们提出了SpERT，一个基于跨度的实体和关系联合提取模型，它依赖于预先训练好的Transformer网络BERT作为其核心。我们的实验表明，通过强负例样本、跨度过滤和本地化的上下文表示，是可以对输入的句子作所有跨度的搜索。我们的结果表明，基于跨度的方法与基于BILOU的模型相比具有竞争力，并且由于其识别重叠实体的能力，可能是未来研究中更有前途的方法。在未来，我们计划研究更详细的关系分类器的上下文形式。目前，我们的模型只是采用了两个实体之间的跨度，这被证明优于完整的上下文。采用额外的 **syntactic features** 或 **learned context**（同时保持高效的穷举搜索）似乎是一个有希望的挑战。

**我的结论**：

文章写的还不错，实验做得很充分，把吹的牛都做出来了，当然还是没有解决相同实体多关系的问题；虽然图画的很丑，但是也太实在了，把错误样本和未来方向全部写出来了，真是个有趣的人！

**更新**：太秀了，我居然还真的发现有人按照作者指出的方向继续做下去了，还超过了原作者的效果并被 COLING 2020 录用了。[Span-based Joint Entity and Relation Extraction with Attention-based Span-specific and Contextual Semantic Representations (aclanthology.org)](https://aclanthology.org/2020.coling-main.8.pdf) 这名字够长的。

那我就继续赶一下，看看这篇“新”论文的亮点在哪里；在此文中，作者明确表明自己是在 SpERT 的基础上继续的，但是在 **span-specific** 和 **contextual semantic representations** 方面有所不同。

> 具体来说，我们的模型通过注意力机制获得这些语义表征。通过计算目标序列语义表征和源序列语义表征之间的匹配程度，注意力机制获得了源序列的注意力分数，这实质上是权重分数。信息越重要，它的权重分数就越高

我前面是不是说 SpERT 的图画的粗糙来着，我后悔了，我收回刚才的话，这个新模型（SPAN）的图更加魔鬼！

![图片](https://xerrors.oss-cn-shanghai.aliyuncs.com/imgs/20210818210829-imagepng)

跨度分类过滤器分为四个部分（图中红色数字）：

1. 跨度头部和尾部表征的连接（首尾拼接）$\mathcal{H}_{\mathrm{s}}=\left[X_{i} ; X_{i+j}\right]$
2. 跨度特定表征 $\mathcal{F}_{\mathbf{s}}=\sum_{m=i}^{i+j} \text{softmax}(\text{MLP}_{m}(X_{m})) \times X_{\mathbf{m}}$
3. 句子层面的上下文表征 $\mathcal{T}_{\mathbf{s}}=$ Attention $\left(\mathcal{F}_{\mathbf{s}}, \mathcal{B}_{\mathcal{S}}, \mathcal{B}_{\mathcal{S}}\right)$
4. 跨度宽度嵌入（我也不知道这是哪里来的）

关系分类器与过滤器分三个部分（图中蓝色数字）：

1. 关系元组表示的串联，两个实体拼一块儿；$\mathcal{H}_{\mathbf{r}}=\left[\mathbf{F F N N}\left(\mathcal{R}_{s_{1}}\right) ; \mathbf{F} \mathbf{F N N}\left(\mathcal{R}_{s_{2}}\right)\right]$
2. 局部语境表示 $\mathcal{F}_{\mathbf{r}}=$ Attention $\left(\mathcal{H}_{\mathbf{r}}, (X_{m},...,X_{m+n}), (X_{m},...,X_{m+n})\right)$
3. 句子级语境表示 $\mathcal{T}_{\mathbf{r}}=\operatorname{Attention}\left(\mathcal{H}_{\mathbf{r}}, \mathcal{B}_{\mathcal{S}}, \mathcal{B}_{\mathcal{S}}\right)$

这下基本上就已经把这个模型给了解了；整体而言，方法没有变，但是在表征方便还是做了不少创新的，比如把之前的 maxpooling 给换成了注意力模块，maxpooling 让我一脸懵。（就是这个图啊，能不能好好画啊）；

实验结果：

![图片](https://xerrors.oss-cn-shanghai.aliyuncs.com/imgs/20210818211615-imagepng)

实验结论：

1. 跨域表征（span-specific representation）和句子级的语境表征（sentence-level contextual representation）**效果很好**。
2. 句子的语义表征对关系分类效果明显，但是对实体识别没有帮助甚至会影响效果（似乎很多论文都论证了这个观点），目前可以的解释是这些表示是简介通过反向传播影响实体的识别效果的。

作者结论：

> 我们在基于跨度的实体和关系联合提取方法中引入了基于注意力的语义表示生成方法。我们应用MLP注意力来捕捉跨度特定的特征，旨在获得语义丰富的跨度表征，并通过注意力架构计算特定任务的上下文表征，进一步加强跨度和关系表征。我们的方法在三个基准数据集上牢牢超过了**基于序列标记**和**基于跨度**的SOTA方法，创造了新的最先进的结果。作为未来的工作，我们希望考虑通过减少跨度分类错误来进一步提高关系分类性能。我们还计划探索**更先进的方法来编码有效的跨度和关系表示**。（考虑一下TPLinker）

我的结论：

效果不错，但感觉这个作者是个新手啊，实验不够充分（hhhh），不过也算是继承了一些优点，提供了新的改进方向。

## 参考资料

太多了
