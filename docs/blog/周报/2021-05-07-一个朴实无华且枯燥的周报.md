---
title: 一个朴实无华且枯燥的周报
date: 2021-05-07 17:01:13
permalink: /2021-05-07-week-post/
cover: https://xerrors.oss-cn-shanghai.aliyuncs.com/imgs/20210430165756-image.png
tags: 
- 周报
categories: 周报
abstract: 测试周报摘要表现情况，最终显示效果以之后的开发为准，现在的设计标准只在于提供一个标准；这里的摘要应该在周报中事先写好，方便之后提取摘要并显示，当长度超过限制的时候可以以省略号显示。
---

## 零散记录

**获取SVM分类器的置信率**

[参考链接](http://scikit-learn.sourceforge.net/stable/modules/generated/sklearn.svm.SVC.html)

```python
# 定义，有的分类器是不需要指定 probability 这个参数的
model = SVC(random_state=0,probability=True)
# 训练
model.fit(data, label)
# 预测
result = model.predict_proba(test)
```

**在线算力平台**

可以考虑的有 [Kaggle](http://kaggle.com/)，Colab，百度的 AI studio。目前我最喜欢的还是 kaggle，首先界面是最好看的，其次上面还有很多比赛，很多代码，更有很多数据集，这对于学习阶段的我无疑是最有吸引力的，之后就在这上面搬砖了。

对于 Colab，使用起来并不是很舒服，感觉谷歌在收购 Kaggle 之后就没有把重心放在 Colab 上面了（亲生的不如领养的），也把很多 Colab 的功能移植到了 Kaggle。

对于百度的 AI studio，很强，给用特斯拉v100，每天10小时！对比之下，kaggle 的特斯拉p100就不够看了；不过百度也不是傻子，想用吗？用飞浆，无法安装 pytorch；鉴于我没学过 paddlepaddle，所以暂时也就不考虑了；不过！如果有时候去跑一些别的模型，社区里面有很多别人训练好的模型，直接用来跑还是不错的，毕竟是特斯拉P100啊。

**DataFrame 一列为 key，一列为 value 转字典**

参考链接：[to_dict](https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.to_dict.html)，[解决方案](https://blog.csdn.net/zx1245773445/article/details/103480750)

默认的有一个 to_dict 方法，但是并不支持上面的需求，所以就需要另外一个方法：

```py
"""
  key  value
0   a      1
1   b      2
"""

data_dict = dict(zip(data['key'],data['value']))
```

当然还有另外一个办法，非常麻烦：

```py
data_dict = data[['key', 'value']].set_index('key').to_dict()['value']
```

## 重点学习

### TransGAN 简单阅读

![图片](https://xerrors.oss-cn-shanghai.aliyuncs.com/imgs/20210510142313-image.png)
知识点记录：

**归纳偏差问题**

> 因为CNN是一个个格子走的（kernel size, pooling layers and so on)，会产生所谓”归纳偏差“（inductive bias）的问题。

文章提出 Transformer 可以对人工定义的“归纳偏差”免疫。

**pixelshuffle 是啥**

Real-time single image and video super-resolution using an efficient sub-pixel convolutional neural network (ESPCN)[链接1](https://link.zhihu.com/?target=https%3A//www.cv-foundation.org/openaccess/content_cvpr_2016/papers/Shi_Real-Time_Single_Image_CVPR_2016_paper.pdf)、[链接2](https://zhuanlan.zhihu.com/p/76338220)

会用到一个周期shuffling算子，将 `H*W*r*r`的向量转化为`rH*rW*C`的向量。

**DiffAugment数据增强**

NIPS2020 - Differentiable Augmentation For Data-Efficient GAN Training。[博客链接](https://link.zhihu.com/?target=https%3A//my.oschina.net/u/4580321/blog/4750605)

**基于“自监督的辅助任务”来进行Co-Training (协同训练）**

![图片](https://xerrors.oss-cn-shanghai.aliyuncs.com/imgs/20210510153711-image.png)

这个图结合这个标题基本上就已经明白是什么意思了，这里使用的是超分辨率的方法。

**自注意力层的局部感知初始化**

不知道

### 自适应实例标准化（Adaptive Instance Normalization，AdaIN）

[参考链接](https://zhuanlan.zhihu.com/p/158657861)

关于 Normalization 到底应该翻译成「标准化」还是「归一化」，我是已经搞不懂了，看的文章都是乱用；不过归一化知识把数据映射到 [0,1] 或者 [-1,1]，而标准化知识将数据按照瞬狙分布将数据转换为标准正态分布，标准化一般情况下都已经达到归一化的目标。

实时的、任意风格的风格迁移（style transfer）方法，将内容图像（content image）特征的均值和方差对齐到风格图像（style image）的均值和方差。此外，这个方法还给用户非常多的控制权，包括内容和风格的折中（trade off），风格插值（混合风格迁移），是否保留颜色，对图像的哪个区域进行风格迁移。

首先是有人发现把 BN 替换成实例标准化可以有效的提高风格迁移的性能，实例标准化的操作跟 Batch 标准化的操作区别就是将范围缩小到了一个实例。

后来有人提出来 Conditional Instance Normalization（CIN），把原本固定的两个超参数变成了可以学习的参数，使用不同的超参数会得到不同的风格迁移结果。

> https://zhuanlan.zhihu.com/p/158657861
> 众所周知（我之前就不知道，孤陋寡闻如我），DNN提取的特征的统计特性可以代表图像的风格[6-8]。Gatys等[9]使用二阶统计特性作为优化目标；Li等[10]发现，对其他统计特性，如channel-wise的均值和方差，进行匹配，对风格迁移也是很有效的。基于上述观察，作者提出，instance normalization通过对特征的统计特性（均值和方差）进行标准化，实现了某种形式的风格标准化（style normalization）。特征的均值和方差就代表着图像的风格！为了验证自己的想法，作者又做了一个实验，先将图像迁移到同一个风格（不是目标风格），然后再进行一次风格迁移（到目标风格），结果如图2中的（c）所示，IN和BN的性能差异减小了很多。迁移到同一个风格后，BN的均值和方差和IN的均值和方差就差不多了（差多少取决于迁移的性能），所以BN和IN的性能就差不多了。没错了，是它，是它，就是它！实锤了，特征的均值和方差就代表着图像的风格！这也就解释了为什么CIN使用不同的超参数对，可以得到不同风格的迁移结果。

### PaddlePaddle

[官网](https://www.paddlepaddle.org.cn/)，贫穷的我租不起服务器，就使用paddlepaddle的吧。正好百度的 AI studio 有一个关于 Transformer 的课程，看一看学一下。[百度顶会论文复现营第2期](https://aistudio.baidu.com/aistudio/education/group/info/21696)。

百度不愧是国产企业，深知调和之道，整个代码风格，看得我一愣一愣的，你可以写得像 tf，也可以写得像 PyTorch，集两家之所长，整体来看，跟 PyTorch 的代码风格还是很像的，这是个好事情，学习与迁移的成本降低，也利于自身的推广。


