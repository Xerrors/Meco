---
title: ACL2021实体关系提取论文阅读笔记
date: 2021-08-22 14:42:07
permalink: /2021-08-22-week-post/
cover: https://xerrors.oss-cn-shanghai.aliyuncs.com/imgs/20210820175248-imagepng
tags: 
- 周报
- 笔记
categories: 周报
abstract: 本周主要将ACL2021中关于关系提取的几篇论文拿出来读一读，并且简单记录一下这些论文的创新点与缺点。
---
本文主要介绍以下四篇论文的进展情况，这里是参考了娄杰大佬整理的ACL清单：[分类汇总 ｜ ACL2021 信息抽取相关论文 (qq.com)](https://mp.weixin.qq.com/s/tLX117eblU8U60qIwhudMg)；更多关系提取相关的论文请参考[这里](https://www.xerrors.fun/2021-08-11-week-post/)的文章，其中第三节部分主要介绍了几种主流的实体关系提取的方法。

顺便说两句，这四篇文章的第一作者都是中国人（看名字和单位应该是），难道国外的大佬都不做关系提取的吗？

## 1. 总览

主要包括：

- PRGC: Potential Relation and Global Correspondence Based Joint Relational Triple Extraction
- Joint Biomedical Entity and Relation Extraction with Knowledge-Enhanced Collective Inference
- UniRE: A Unified Label Space for Entity Relation Extraction
- Dependency-driven Relation Extraction with Attentive Graph Convolutional Networks

## 2. 详细笔记

此段可略过：闲扯两句，看了这么久才发现，这些论文的参考文献是按照姓氏的首字母排序的！不过确实这样比较合理，我特别喜欢这种参考文献的方式，文中能够直接看到作者的姓氏和年份，这样就能够判断是不是自己之前看过的论文，如果不是很确定，也可以快速的按照姓氏到后面的参考文献里面去比对论文的标题！

### 基于潜在关系和全局对应关系（PRGC）

论文在此：[PRGC: Potential Relation and Global Correspondence Based Joint Relational Triple Extraction (aclanthology.org)](https://aclanthology.org/2021.acl-long.486.pdf)

先看摘要：

> 从非结构化文本中联合提取实体和关系是信息提取的一项重要任务。最近的方法取得了可观的性能，但仍有一些固有的局限性，如**关系预测的冗余性**，基于跨度的提取的**通用性差和效率低下**。
>
> 在本文中，我们从一个**新的角度**将这一任务分解为三个子任务，即**关系判断**、**实体提取**和**主宾语对齐**，然后提出了一个**基于潜在关系和全局对应关系（PRGC）的联合关系三元组提取框架**。
>
> 具体来说，我们设计了一个预测潜在关系的组件，它将下面的实体提取限制在预测的关系子集上，而不是所有的关系；然后应用一个特定关系的序列标签组件来处理主体和客体之间的重叠问题；最后，设计了一个全局对应组件来将主语和宾语以**低复杂度**对齐成一个三元组。
>
> 广泛的实验表明，PRGC在公共基准上实现了最先进的性能，具有更高的效率，并在三元组重叠的复杂场景中实现了一致的性能提升。

在我看来，文章的出发点在于解决之前模型的计算效率低下问题，首先作者认为基于跨度的提取方法仅仅关注**实体的起止坐标**，导致泛化性能很差（作者未做解释）；作者还认为当前 SOTA 的 TPLinker 在每个句子的每个关系都使用了两个 $O(n^2)$ 的矩阵，导致极度的冗余，同时还拥有基于跨度算法的通病。

下面是模型的结构图，重点是画虚线的是三个部分；摘要中，实体关系提取任务分成了三个部分，分别对应图中的三个组件：

1. 关系判断：（橙色虚线）Potential Relation Prediction
2. 实体提取：（蓝色虚线）Relation-Specific Sequence Taggers
3. 主宾语对齐：（绿色虚线）Global Correspondence

请允许我吐槽一下论文中各个公式的写法，字母混用！公式(1)(2)(3)全部都是使用字母 P 来表示输出，我不理解为什么要这样；比如图中橙色部分的输出，即句子中可能存在的关系，是使用 $\mathbf{R}^{pot}$ 来表示的，而公式中是使用 $P_{rel}$ 表示这个数组中一个元素的；公式乱的一塌糊涂！接下来的所有公示中，我会使用 $\mathbf{P}_{sub, obj} \in \mathbb{R}^{n \times n}$ 来表示实体对应关系；使用 $\mathbf{R}^{pot} \in \mathbb{R} ^ {n_r \times 1}$ 来表示潜在的关系向量；使用 $\mathbf{E}^{sub},\mathbf{E}^{obj} \in \mathbb{R}^{n \times m}$；其中 $n$ 是句子序列中的 tokens 的个数，$n_r$ 表示所有的关系的个数，$m$ 的是指潜在的关系的个数；

在介绍具体的公式之前，我先简述一下整个过程；首先是对输入的句子进行编码，得到 $\mathbf{h}$ ，这时候同时执行两个操作，即图中的绿色部分和橙色部分，绿色部分表示全局对应关系，是个 $n \times n$ 的矩阵，表示两个位置之间的主宾语对应关系，有关系为 1 没关系为 0；橙色部分表示预测潜在的关系，是个长度为 $n_r$ 的向量，表示所有的关系的状态，标记 1 表示是这个句子中可能存在的关系，0 表示不是这个句子中可能存在的关系（这个想法真的不错）。

然后针对已经提取出来的潜在关系以及句子编码 $h$ ，执行图中蓝色虚线部分的任务，针对可能存在的 $m$ 个关系中的每个关系，都计算出该关系对应的主语和宾语的实体标记（BIO），可能有多个，得到一个序列表 $ 2\times n$；

所以现在我们数一数我们有什么，我们有实体关系矩阵表、潜在的关系表、全局对应表；然后对于这三个输出对照标签数据计算他们的交叉熵损失，加权求和之后就是最终的损失。

![图片](https://xerrors.oss-cn-shanghai.aliyuncs.com/imgs/20210822212611-imagepng)

**关系判断**：输入是句子的特征向量 $\mathbf{h}$，这个是 BERT 等预训练模型编码器的输出，然后输出是 $\boldsymbol{R}^{pot}$；是一个一维的向量，

$$
\begin{aligned}
\mathbf{h}^{\text {avg }} &=\text { Avgpool }(\mathbf{h}) \in \mathbb{R}^{d \times 1} \\
\mathbf{R}^{pot}_{i} &=\sigma\left(\mathbf{W}_{r, i} \mathbf{h}^{\text {avg }}+\mathbf{b}_{r,i}\right)
\end{aligned}

$$

其中 $\mathbf{W}_{r} \in \mathbb{R} ^ {d \times n_r}$ 和 $\mathbf{b}_r$ 是可训练的参数；就是说这个组件进行的计算就是一个平均池化、一个全连接层和一个激活函数，从 sigmoid 函数可以看出来，这是一个多标签的二分类问题；

**实体提取**：输入是句子的特征向量 $\mathbf{h}$，以及潜在的关系 $\mathbf{R}^{pot}$；

$$
\begin{array}{r}
\mathbf{E}_{i, j}^{sub}=\operatorname{Softmax}\left(\mathbf{W}_{s u b}\left(\mathbf{h}_{i}+\mathbf{u}_{j}\right)+\mathbf{b}_{s u b}\right) \\
\mathbf{E}_{i, j}^{obj}=\operatorname{Softmax}\left(\mathbf{W}_{o b j}\left(\mathbf{h}_{i}+\mathbf{u}_{j}\right)+\mathbf{b}_{o b j}\right)
\end{array}

$$

其中 $\mathbf{u}_j \in \mathbb{R}^{d \times 1}$ 表示可训练学习的矩阵 $\mathbf{U} \in \mathbb{R}^{d \times n_r}$ 第 $j$ 个关系表征；总的来说，也就是一个全连接一个激活函数就完成了。公式中的 $j$ 是使用 $\boldsymbol{R}^{pot}$ 为 1 的位置的 $j$；

**主宾语对齐**：这里是计算主语和宾语的对应关系，是一个二维矩阵，矩阵中的每个元素 $\mathbf{P}_{i, j}$ 表示第 $i$ 个起始坐标的实体和第 $j$ 个起始坐标的实体是主语和宾语关系的置信度；具体计算方法就是把两个实体的 token 直接拼接之后经过一个全连接和 sigmoid 激活函数。这里的对齐过程是可以跟关系预测过程（橙色部分）并行进行的。

$$
\mathbf{P}_{i, j} = \sigma (\mathbf{W}_{g} [ \mathbf{h}_{i}; \mathbf{h}_{j}] + \mathbf{b}_{g})

$$

终于介绍完这些恶心的公式了，明明很简单的任务却要写的这么复杂，直接说自己额外创建了几个子任务并针对子任务定制了损失函数来达到多任务学习的目的；全文连一个多任务都没出现，不知道是怎么想的。

实验结果：

![图片](https://xerrors.oss-cn-shanghai.aliyuncs.com/imgs/20210823101006-imagepng)

接下来说说这个实验结果的对比，嗯很好，不过我不太喜欢作者在文中所提到的：

> 有一点很重要的是，尽管 TPlinker 比 CasRel 的参数量要多，但是在 WebNLG 数据集上却仅仅提升了 0.1%，并且 TPLinker 作者把这个问题归咎于数据集本身的问题；然而，我们的模型在 WebNLG 数据集上得到了 10 倍于 TPLinker 的提升效果；

我承认，你使用潜在的关系这个做法非常的巧妙，也大大减少了参数量和计算量，但是你这 1.2% 的**性能提升**，不值得你这么吹牛吧 ，更何况你这 93% 的分数也不是 SOTA 吧，你为什么不对比 2020 年就已经登顶的 SOTA [SPN]([arxiv.org](https://arxiv.org/abs/2011.01675v2)) 呢？而且榜单([Relation Extraction | Papers With Code](https://paperswithcode.com/task/relation-extraction))上也没你啊。

![图片](https://xerrors.oss-cn-shanghai.aliyuncs.com/imgs/20210823101915-imagepng)

好的，那我们来比对一下**计算效率问题**：

图 a 取自 TPLinker Table 4：[2010.13415.pdf (arxiv.org)](https://arxiv.org/pdf/2010.13415.pdf)

![图片](https://xerrors.oss-cn-shanghai.aliyuncs.com/imgs/20210823104832-imagepng)

图 b 取自 PRGC Table 6：[PRGC (aclanthology.org)](https://aclanthology.org/2021.acl-long.486.pdf)

![图片](https://xerrors.oss-cn-shanghai.aliyuncs.com/imgs/20210823104920-imagepng)

图 a 是  TPLinker 所放出的参数量以及推理时间的结果，图 b 是 PRGC 论文中的结果。这里的参数量你告诉我有什么意义呢？你不把 BERT 的参数量算进去，你只看后部分的参数量和推理时间并没有太大的实战意义。

那么最后就是**通用性**泛化能力的问题了，不得不说作者的实验做的是真滴牛批，

![图片](https://xerrors.oss-cn-shanghai.aliyuncs.com/imgs/20210823115942-imagepng)

这里是做实验说明自己的 Rel-Spec Sequence Tagging 模块比 span-base 的模块效果要好，注意看第二行，找你这么说，这个模块还真是差到离谱了；你把 AK-47 的弹夹换成 M2 的弹夹，发现效果变化很大，然后你就得出来 M2 不如 AK-47 是吗？就离谱（我不懂军事，我就是举个例子，不能通过单纯换组件来证明自己的观点，毕竟你们连个模型在策略上就差别很大）；你可以说你的这个新模块是有用的，是可行的；而不是吹自己踩别人，毕竟你这样的实验并不具备说服力。

再看看你这举的例子，你觉得有说服性吗？什么时候比较通用性可以通过一两个示例来说明了？你就全是对的，别人的就全是错的？更何况你这两个例子跟通用性有什么关系？我这边建议作者有空看看这篇论文：[1283_paper.pdf (ecai2020.eu)](https://ecai2020.eu/papers/1283_paper.pdf)，同样是写论文，你看看这气度，人家没有踩别人，还仔细分析了自己的错误示例，还给之后的研究指出了方向，以至于后续刚好有人在他的基础上做出了更好的效果。而不是像这个作者这样心胸狭隘！

![图片](https://xerrors.oss-cn-shanghai.aliyuncs.com/imgs/20210823120439-imagepng)

> 通过图3（上图）所示的案例研究，我们发现 span-based 方案倾向于提取长实体并识别正确的主宾语对，但忽略了它们之间的关系。这是因为模型倾向于记住实体的位置，而不是理解底层语义（猜测而已）。然而，PRGC使用的序列标记方案**在这两种情况下**都表现良好，实验结果证明我们的标记方案更具健壮性和通用性。

就很无语！一个劲的吹自己的效率高，速度快。我都要被恶心到了！
