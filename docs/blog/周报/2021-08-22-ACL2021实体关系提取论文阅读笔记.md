---
title: ACL2021实体关系提取论文阅读笔记
date: 2021-08-22 14:42:07
permalink: /2021-08-22-week-post/
cover: https://xerrors.oss-cn-shanghai.aliyuncs.com/imgs/20210820175248-imagepng
tags: 
- 周报
- 笔记
categories: 周报
abstract: 本周主要将ACL2021中关于关系提取的几篇论文拿出来读一读，并且简单记录一下这些论文的创新点与缺点。
---
本文主要介绍以下三篇论文的进展情况，这里是参考了娄杰大佬整理的ACL清单：[分类汇总 ｜ ACL2021 信息抽取相关论文 (qq.com)](https://mp.weixin.qq.com/s/tLX117eblU8U60qIwhudMg)；更多关系提取相关的论文请参考[这里](https://www.xerrors.fun/2021-08-11-week-post/)的文章，其中第三节部分主要介绍了几种主流的实体关系提取的方法。

顺便说两句，这三篇文章的第一作者都是中国人（看名字和单位应该是），难道国外的大佬都不做关系提取的吗？

## 1. 总览

主要包括：

- [PRGC: Potential Relation and Global Correspondence Based Joint Relational Triple Extraction (aclanthology.org)](https://aclanthology.org/2021.acl-long.486.pdf)
- [Joint Biomedical Entity and Relation Extraction with Knowledge-Enhanced Collective Inference (aclanthology.org)](https://aclanthology.org/2021.acl-long.488.pdf)
- [UniRE: A Unified Label Space for Entity Relation Extraction (arxiv.org)](https://arxiv.org/pdf/2107.04292.pdf)

## 2. 详细笔记

此段可略过：闲扯两句，看了这么久才发现，这些论文的参考文献是按照姓氏的首字母排序的！不过确实这样比较合理，我特别喜欢这种参考文献的方式，文中能够直接看到作者的姓氏和年份，这样就能够判断是不是自己之前看过的论文，如果不是很确定，也可以快速的按照姓氏到后面的参考文献里面去比对论文的标题！

### 基于潜在关系和全局对应关系（PRGC）

论文在此：[PRGC: Potential Relation and Global Correspondence Based Joint Relational Triple Extraction (aclanthology.org)](https://aclanthology.org/2021.acl-long.486.pdf)

先看摘要：

> 从非结构化文本中联合提取实体和关系是信息提取的一项重要任务。最近的方法取得了可观的性能，但仍有一些固有的局限性，如**关系预测的冗余性**，基于跨度的提取的**通用性差和效率低下**。
>
> 在本文中，我们从一个**新的角度**将这一任务分解为三个子任务，即**关系判断**、**实体提取**和**主宾语对齐**，然后提出了一个**基于潜在关系和全局对应关系（PRGC）的联合关系三元组提取框架**。
>
> 具体来说，我们设计了一个预测潜在关系的组件，它将下面的实体提取限制在预测的关系子集上，而不是所有的关系；然后应用一个特定关系的序列标签组件来处理主体和客体之间的重叠问题；最后，设计了一个全局对应组件来将主语和宾语以**低复杂度**对齐成一个三元组。
>
> 广泛的实验表明，PRGC在公共基准上实现了最先进的性能，具有更高的效率，并在三元组重叠的复杂场景中实现了一致的性能提升。

在我看来，文章的出发点在于解决之前模型的计算效率低下问题，首先作者认为基于跨度的提取方法仅仅关注**实体的起止坐标**，导致泛化性能很差（作者未做解释）；作者还认为当前 SOTA 的 TPLinker 在每个句子的每个关系都使用了两个 $O(n^2)$ 的矩阵，导致极度的冗余，同时还拥有基于跨度算法的通病。

#### 模型介绍

下面是模型的结构图，重点是画虚线的是三个部分；摘要中，实体关系提取任务分成了三个部分，分别对应图中的三个组件：

1. 关系判断：（橙色虚线）Potential Relation Prediction
2. 实体提取：（蓝色虚线）Relation-Specific Sequence Taggers
3. 主宾语对齐：（绿色虚线）Global Correspondence

请允许我吐槽一下论文中各个公式的写法，字母混用！公式(1)(2)(3)全部都是使用字母 P 来表示输出，我不理解为什么要这样；比如图中橙色部分的输出，即句子中可能存在的关系，是使用 $\mathbf{R}^{pot}$ 来表示的，而公式中是使用 $P_{rel}$ 表示这个数组中一个元素的；公式乱的一塌糊涂！接下来的所有公示中，我会使用 $\mathbf{P}_{sub, obj} \in \mathbb{R}^{n \times n}$ 来表示实体对应关系；使用 $\mathbf{R}^{pot} \in \mathbb{R} ^ {n_r \times 1}$ 来表示潜在的关系向量；使用 $\mathbf{E}^{sub},\mathbf{E}^{obj} \in \mathbb{R}^{n \times m}$；其中 $n$ 是句子序列中的 tokens 的个数，$n_r$ 表示所有的关系的个数，$m$ 的是指潜在的关系的个数；

在介绍具体的公式之前，我先简述一下整个过程；首先是对输入的句子进行编码，得到 $\mathbf{h}$ ，这时候同时执行两个操作，即图中的绿色部分和橙色部分，绿色部分表示全局对应关系，是个 $n \times n$ 的矩阵，表示两个位置之间的主宾语对应关系，有关系为 1 没关系为 0；橙色部分表示预测潜在的关系，是个长度为 $n_r$ 的向量，表示所有的关系的状态，标记 1 表示是这个句子中可能存在的关系，0 表示不是这个句子中可能存在的关系（这个想法真的不错）。

然后针对已经提取出来的潜在关系以及句子编码 $h$ ，执行图中蓝色虚线部分的任务，针对可能存在的 $m$ 个关系中的每个关系，都计算出该关系对应的主语和宾语的实体标记（BIO），可能有多个，得到一个序列表 $ 2\times n$；

所以现在我们数一数我们有什么，我们有实体关系矩阵表、潜在的关系表、全局对应表；然后对于这三个输出对照标签数据计算他们的交叉熵损失，加权求和之后就是最终的损失。

![图片](https://xerrors.oss-cn-shanghai.aliyuncs.com/imgs/20210822212611-imagepng)

**关系判断**：输入是句子的特征向量 $\mathbf{h}$，这个是 BERT 等预训练模型编码器的输出，然后输出是 $\boldsymbol{R}^{pot}$；是一个一维的向量，

$$
\begin{aligned}
\mathbf{h}^{\text {avg }} &=\text { Avgpool }(\mathbf{h}) \in \mathbb{R}^{d \times 1} \\
\mathbf{R}^{pot}_{i} &=\sigma\left(\mathbf{W}_{r, i} \mathbf{h}^{\text {avg }}+\mathbf{b}_{r,i}\right)
\end{aligned}

$$

其中 $\mathbf{W}_{r} \in \mathbb{R} ^ {d \times n_r}$ 和 $\mathbf{b}_r$ 是可训练的参数；就是说这个组件进行的计算就是一个平均池化、一个全连接层和一个激活函数，从 sigmoid 函数可以看出来，这是一个多标签的二分类问题；

**实体提取**：输入是句子的特征向量 $\mathbf{h}$，以及潜在的关系 $\mathbf{R}^{pot}$；

$$
\begin{array}{r}
\mathbf{E}_{i, j}^{sub}=\operatorname{Softmax}\left(\mathbf{W}_{s u b}\left(\mathbf{h}_{i}+\mathbf{u}_{j}\right)+\mathbf{b}_{s u b}\right) \\
\mathbf{E}_{i, j}^{obj}=\operatorname{Softmax}\left(\mathbf{W}_{o b j}\left(\mathbf{h}_{i}+\mathbf{u}_{j}\right)+\mathbf{b}_{o b j}\right)
\end{array}

$$

其中 $\mathbf{u}_j \in \mathbb{R}^{d \times 1}$ 表示可训练学习的矩阵 $\mathbf{U} \in \mathbb{R}^{d \times n_r}$ 第 $j$ 个关系表征；总的来说，也就是一个全连接一个激活函数就完成了。公式中的 $j$ 是使用 $\boldsymbol{R}^{pot}$ 为 1 的位置的 $j$；

**主宾语对齐**：这里是计算主语和宾语的对应关系，是一个二维矩阵，矩阵中的每个元素 $\mathbf{P}_{i, j}$ 表示第 $i$ 个起始坐标的实体和第 $j$ 个起始坐标的实体是主语和宾语关系的置信度；具体计算方法就是把两个实体的 token 直接拼接之后经过一个全连接和 sigmoid 激活函数。这里的对齐过程是可以跟关系预测过程（橙色部分）并行进行的。

$$
\mathbf{P}_{i, j} = \sigma (\mathbf{W}_{g} [ \mathbf{h}_{i}; \mathbf{h}_{j}] + \mathbf{b}_{g})

$$

终于介绍完这些恶心的公式了，明明很简单的任务却要写的这么复杂，直接说自己额外创建了几个子任务并针对子任务定制了损失函数来达到多任务学习的目的；全文连一个多任务都没出现，不知道是怎么想的。

#### 实验表现

![图片](https://xerrors.oss-cn-shanghai.aliyuncs.com/imgs/20210823101006-imagepng)

接下来说说这个实验结果的对比，嗯很好，不过我不太喜欢作者在文中所提到的：

> 有一点很重要的是，尽管 TPlinker 比 CasRel 的参数量要多，但是在 WebNLG 数据集上却仅仅提升了 0.1%，并且 TPLinker 作者把这个问题归咎于数据集本身的问题；然而，我们的模型在 WebNLG 数据集上得到了 10 倍于 TPLinker 的提升效果；

我承认，你使用潜在的关系这个做法非常的巧妙，也大大减少了参数量和计算量，但是你这 1.2% 的**性能提升**，不值得你这么吹牛吧 ，更何况你这 93% 的分数也不是 SOTA 吧，你为什么不对比 2020 年就已经登顶的 SOTA [SPN]([arxiv.org](https://arxiv.org/abs/2011.01675v2)) 呢？而且榜单([Relation Extraction | Papers With Code](https://paperswithcode.com/task/relation-extraction))上也没你啊。

![图片](https://xerrors.oss-cn-shanghai.aliyuncs.com/imgs/20210823101915-imagepng)

好的，那我们来比对一下**计算效率问题**：

图 a 取自 TPLinker Table 4：[2010.13415.pdf (arxiv.org)](https://arxiv.org/pdf/2010.13415.pdf)

![图片](https://xerrors.oss-cn-shanghai.aliyuncs.com/imgs/20210823104832-imagepng)

图 b 取自 PRGC Table 6：[PRGC (aclanthology.org)](https://aclanthology.org/2021.acl-long.486.pdf)

![图片](https://xerrors.oss-cn-shanghai.aliyuncs.com/imgs/20210823104920-imagepng)

图 a 是  TPLinker 所放出的参数量以及推理时间的结果，图 b 是 PRGC 论文中的结果。这里的参数量你告诉我有什么意义呢？你不把 BERT 的参数量算进去，你只看后部分的参数量和推理时间并没有太大的实战意义。

那么最后就是**通用性**泛化能力的问题了，不得不说作者的实验做的是真滴牛批，

![图片](https://xerrors.oss-cn-shanghai.aliyuncs.com/imgs/20210823115942-imagepng)

这里是做实验说明自己的 Rel-Spec Sequence Tagging 模块比 span-base 的模块效果要好，注意看第二行，找你这么说，这个模块还真是差到离谱了；你把 AK-47 的弹夹换成 M2 的弹夹，发现效果变化很大，然后你就得出来 M2 不如 AK-47 是吗？就离谱（我不懂军事，我就是举个例子，不能通过单纯换组件来证明自己的观点，毕竟你们连个模型在策略上就差别很大）；你可以说你的这个新模块是有用的，是可行的；而不是吹自己踩别人，毕竟你这样的实验并不具备说服力。

再看看你这举的例子，你觉得有说服性吗？什么时候比较通用性可以通过一两个示例来说明了？你就全是对的，别人的就全是错的？更何况你这两个例子跟通用性有什么关系？我这边建议作者有空看看这篇论文：[1283_paper.pdf (ecai2020.eu)](https://ecai2020.eu/papers/1283_paper.pdf)，同样是写论文，你看看这气度，人家没有踩别人，还仔细分析了自己的错误示例，还给之后的研究指出了方向，以至于后续刚好有人在他的基础上做出了更好的效果。而不是像你这样心胸狭隘！

![图片](https://xerrors.oss-cn-shanghai.aliyuncs.com/imgs/20210823120439-imagepng)

> 通过图3（上图）所示的案例研究，我们发现 span-based 方案倾向于提取长实体并识别正确的主宾语对，但忽略了它们之间的关系。这是因为模型倾向于记住实体的位置，而不是理解底层语义（猜测而已）。然而，PRGC使用的序列标记方案**在这两种情况下**都表现良好，实验结果证明我们的标记方案更具健壮性和通用性。

**作者结论**：

> 本文提出了一种全新的视角，提出了一种基于潜在关系和全局对应的联合关系抽取框架，极大地缓解了冗余关系判断、基于广度的抽取泛化能力差和主宾语对齐效率低的问题。实验结果表明，我们的模型在公共数据集中实现了最先进的性能，并以更高的效率成功地处理了许多复杂场景。

**我的结论**：

嗯，就很无语！一个劲的吹自己的效率高，速度快。我都要被恶心到了！啥也不是！

### 利用知识增强的集体推理进行生物医学实体和关系的联合提取

论文在此：[Joint Biomedical Entity and Relation Extraction with Knowledge-Enhanced Collective Inference (aclanthology.org)](https://aclanthology.org/2021.acl-long.488.pdf)

先看摘要：

> 与一般的新闻领域相比，**生物医学文本的信息提取**（IE）需要更广泛的领域知识。然而，以前的许多 IE 方法在推理过程中没有利用任何外部知识。由于生物医学出版物的指数级增长，那些没有超越其固定参数集的模型很可能会落后。受人类如何查找相关信息以理解科学文本的启发，我们提出了一个**新的框架，利用外部知识进行联合实体和关系提取**，命名为**KECI（知识增强集体推理）**。给定一个输入文本，KECI首先构建一个**初始跨度图**，代表其对文本的初始理解。然后，它使用一个**实体链接器**来形成一个**知识图**，包含文本中提到的实体的相关背景知识。为了做出最终的预测，**KECI使用注意力机制将初始跨度图和知识图融合成一个更精细的图**。KECI采取了一种集体的方法，通过**使用图卷积网络**将全局关系信息整合到局部表示中，将提及跨度与实体联系起来。我们的实验结果表明，该框架是非常有效的，在两个不同的基准数据集中取得了新的先进成果。BioRelEx（结合作用检测）和ADE（药物不良事件提取）。例如，在BioRelEx实体和关系提取任务中，KECI的F1得分比最先进的技术分别提高了4.59%和4.91%。

由于图卷积和生物医学文本的信息提取并不是很了解，所以这一篇文章主要是一个略读的简单笔记。

> 总的来说，KECI的设计部分地受到了以前教育心理学研究的启发。学生的背景知识在指导他们对科学文本的理解和理解方面起着至关重要的作用（Alvermann等人，1985；Braasch和Goldman，2010）。"激活 "相关和准确的先前知识将有助于学生的阅读理解。

有一说一，这个作者的公式写的是真的清楚，解释的也清楚，很好理解！

#### 模型介绍

把文本变成关系三元组，总共分四步：

![图片](https://xerrors.oss-cn-shanghai.aliyuncs.com/imgs/20210823214226-imagepng)

**第 0 步，跨度编码**；

即把句子中所有长度不超过 L 的跨度进行编码，编码的方式很简单，使用该跨度一些基本信息传入到一个前馈神经网络里面就行了，这些基本信息包括：起始位置的特征向量、结束位置的特征向量、该跨度表征中的注意力加权和以及表示跨度长度的特征向量；每个跨度的输出的维度是 d。

$$
\mathbf{s}_{i}=\mathrm{FF} \mathbf{N N}_{\mathrm{g}}\left(\left[\mathbf{x}_{\mathrm{START}(i)}, \mathbf{x}_{\mathrm{END}(i)}, \hat{\mathbf{x}}_{i}, \phi\left(\mathbf{s}_{i}\right)\right]\right)

$$

**第 1 步，构建初始的跨度图**；

预测实体以及预测关系，有了每个跨度的特征向量之后，直接预测这些跨度是哪些实体，跨度之间两两是否有关系；

$$
\begin{aligned}
\mathbf{e}_{i}&=\operatorname{Softmax}\left(\mathrm{FFNN}_{e}\left(\mathbf{s}_{i}\right)\right) \\
\mathbf{r}_{i,j}&=\operatorname{Softmax}\left(\operatorname{FFNN}_{r}\left(\left[\mathbf{s}_{i}, \mathbf{s}_{j}, \mathbf{s}_{i} \circ \mathbf{s}_{j}\right]\right)\right)
\end{aligned}

$$

对于每一个跨度而言，实体的输出 $e_i$ 是该跨度 $s_i$ 是某个实体的概率，一个长度为 $|E|$ 的概率向量；而关系的输出是一个全局的矩阵，假设有 $m$ 个跨度，那么矩阵的维度就是 $m\times m \times |R|$，$r_{i,j}[k]$ 表示跨度 $s_i$ 和 $s_j$ 具有关系 $k$ 的概率；

有了这些之后我们不就得到最后的输出了吗（不是）；接下来才是重点，接下来把每个跨度作为一个节点，把这些节点全部两两用 $|R|$ 条线连起来，每两个跨度之间的每个关系的概率就是每根线的权重，这不就构成了一个大图了吗；

之后就利用这些节点和边使用双向 GCN 来迭代更新每个节点的值，更新迭代后的节点的值使用 $\mathbf{h}_i$ 表示；

$$
\begin{aligned}
\overrightarrow{\mathbf{h}_{i}^{l}} &=\sum_{s_{j} \in V_{s} \backslash\left\{s_{i}\right\}} \sum_{k \in R} \mathbf{r}_{i j}[k]\left(\overrightarrow{\mathbf{\mathbf { W }}_{k}^{(l)}} \mathbf{h}_{j}^{l}+\overrightarrow{\mathbf{b}_{k}^{({l})}}\right) \\

\overleftarrow{\mathbf{h}_{i}^{l}} &=\sum_{s_{j} \in V_{s} \backslash\left\{s_{i}\right\}} \sum_{k \in R} \mathbf{r}_{j i}[k]\left(\overleftarrow{\mathbf{W}_{k}^{(l)}} \mathbf{h}_{j}^{l}+\overleftarrow{\mathbf{b}_{k}^{(l)}}\right)\\

\mathbf{h}_{i}^{l+1} &=\mathbf{h}_{i}^{l}+\mathrm{FFNN}_{a}^{(l)}\left(\operatorname{ReLU}\left(\left[\overrightarrow{\mathbf{h}_{i}^{l}}, \overleftarrow{\mathbf{h}_{i}^{l}}\right]\right)\right)
\end{aligned}

$$

**第 2 步，构建背景知识图**；

嗯，看不懂，下面的可以不看，只需要知道得到了一个图 $G_k$；节点是 $n_i$；

> 我们首先使用MetaMap从输入文档D中提取 UMLS 生物医学实体，这是一个UMLS的实体映射工具（Aronson and Lang, 2010）。然后我们从提取的信息中构建一个背景知识图（KG）。
>
> 更具体地说，我们首先为每个提取的**生物医学实体**创建一个**节点**。每个实体节点的**语义类型**也被建模为**类型节点**，**与相关的实体节点相连**。
>
> 最后，我们为元词库和语义网络中发现的每一个相关关系创建一条边。图2中的灰色阴影区域就是一个KG的例子。圆圈代表实体节点，矩形代表对应于语义类型的节点。
>
> 请注意，我们只是用默认选项运行MetaMap，并没有对其进行调整。在我们的实验中，我们发现，MetaMap通常会返回许多与输入文本无关的候选实体。然而，正如第3.4节所讨论的，实验表明 KECI 可以学会忽略不相关的实体。
>
> 让$G_k= \{V_k, E_k\}$表示构建的背景 KG，其中$V_k$和$E_k$分别是节点和边集。我们使用由Maldonado等人（2019）预训练的一组 UMLS 嵌入来初始化 $V_k$ 中每个节点的表示。我们还使用SciBERT 将每个节点的 UMLS 定义句子编码为一个向量，并将其与初始表示相连接。之后，由于$G_k$是一个异质关系图，我们使用关系型GCN（Schlichtkrull等人，2018）来更新每个节点 $v_i$ 的表示。

![图片](https://xerrors.oss-cn-shanghai.aliyuncs.com/imgs/20210823214552-imagepng)

> 在进行多次信息传递的迭代后，KG的全局关系信息将被整合到每个节点的表示中。$v_i$ 表示关系型 GCN 的最后一层的特征向量。我们使用一个简单的前馈网络将每个向量 $v_i$ 进一步投射到另一个向量 $n_i$ 上，这样 $n_i$ 的维度与跨度表示相同。

**第 3 步，图预测;**

不管看没看懂，现在有两个图了 $G_s$ 和 $G_k$；那么接下来，我们首先计算出 $G_s$ 的每个跨度节点的候选实体 $C(s_i)$（怎么算的？），即结构图中每个节点虚线相连的部分，同时针对每个跨度节点与候选实体计算他们之间的相关分数；同时计算一个额外的 **sentinel vector**（守卫向量？）以及相关分数；这里的守卫向量记录了跨度的本地语境信息，守卫向量的相关分数表示这个信息的重要程度。之后就能得到每个跨度 $s_i$ 的**知识感知**的特征向量 $\mathbf{f}_i$；

这个注意力机制计算方法如下图和公式所示，看图理解就好理解了：

![图片](https://xerrors.oss-cn-shanghai.aliyuncs.com/imgs/20210823221318-imagepng)

这时候上面的 $\mathbf{f_i}$ 就包含了之前的全局的实体关系表征信息、与背景知识图谱对应的实体的知识信息、候选实体的加权信息，所以是时候直接利用这些表征来预测真正的实体和实体之间的关系了！

$$
\begin{aligned}
\widehat{\mathbf{e}_{i}} &=\operatorname{Softmax}\left(\mathrm{FFNN}_{\widehat{e}}\left(\mathbf{f}_{i}\right)\right) \\
\widehat{\mathbf{r}_{i j}} &=\operatorname{Softmax}\left(\operatorname{FFNN}_{\widehat{r}}\left(\left[\mathbf{f}_{i}, \mathbf{f}_{j}, \mathbf{f}_{i} \circ \mathbf{f}_{j}\right]\right)\right)
\end{aligned}

$$

计算方法跟前面相似；

那么关于损失函数就是同时包含了初始的那次预测的交叉熵损失以及最终的这次预测的交叉熵损失，只是后者的权重比较高。

$$
\mathcal{L}_{\text {total }}=\left(\mathcal{L}_{1}^{e}+\mathcal{L}_{1}^{r}\right)+2\left(\mathcal{L}_{2}^{e}+\mathcal{L}_{2}^{r}\right)

$$

#### 实验表现

![图片](https://xerrors.oss-cn-shanghai.aliyuncs.com/imgs/20210823222750-imagepng)

除了之前的几个模型以外，作者还创建了几个额外的基线模型，比如只使用本地的语境来预测 SentContextOnly、不使用图卷积 FlatAttention、把第二部分即灰色的那一块替换成 KnowBertAttention 模块，这个模块具体的我就不琢磨了，可以参考[这里](https://doi.org/10.18653/v1/D19-1005)；

上面的数据已经可以说明效果了，那么作者也指出了目前模型所存在的问题，即数据集中的实体提及和UMLS实体之间没有 gold 标准的对应关系集。因此，不能直接评估 KECI 的实体链接性能。但是作者记录了该类型的实体被分配的平均注意力权重（没读懂这是啥），发现模型最关注相关的信息实体，而忽略不相关的实体。

![图片](https://xerrors.oss-cn-shanghai.aliyuncs.com/imgs/20210823224103-imagepng)

下图的三个例子说明基于 UMLS 的图谱可以正确的连接实体的关系、减去不存在的关系、修正错误的实体类型；但是一个**主要问题**是，MetaMap有时不能从 UMLS 中为一个实体的 mention 返回任何候选实体。我们把这项工作扩展到使用多个知识库作为未来的工作。

**作者结论**：

> 在这项工作中，我们提出了一个新的基于跨度的框架，名为KECI，利用外部领域知识从生物医学文本中联合提取实体和关系。实验结果表明，KECI是非常有效的，在两个数据集上取得了新的先进的结果。BioRelEx和ADE。理论上，KECI可以将整个文档作为输入；但是，测试的数据集只是句子级的数据集。在未来，我们计划在更多的文档级数据集上评估我们的框架。我们还计划探索更广泛的可以从外部知识库中提取的属性和信息，以促进生物医学的 IE 任务。最后，我们还计划将KECI应用于其他信息提取任务；

**我的结论**：

这篇文章是我见到的第一个把相关工作放在实验后面的；作者的想法以及实验结果都是有效的，是个很有意义的尝试（当然可能并不是独创的）；不过也确实可能说明利用外部的背景知识可以针对特定领域的任务进行优化；而且这种优化也不需要很多的人工成本，是可以简单的把相同的方法用在其他领域的。

### 利用统一标签空间的提取方法

论文在此：[UniRE: A Unified Label Space for Entity Relation Extraction (arxiv.org)](https://arxiv.org/pdf/2107.04292.pdf)

先看摘要：

> 许多联合实体关系提取模型为两个子任务（即实体检测和关系分类）设置了两个分离的标签空间。我们认为，这种设置可能会阻碍实体和关系之间的信息交互。在这项工作中，我们建议**消除对两个子任务的标签空间的不同处理**。我们模型的输入是一个包含一个句子中所有词对的**表格**。实体和关系在表中用正方形和长方形表示。我们应用一个统一的分类器来预测每个单元格的标签，这统一了两个子任务的学习。为了测试，我们提出了一个有效的（但快速的）近似解码器，用于从表中寻找正方形和矩形。在三个基准（ACE04, ACE05, SciERC）上的实验表明，只用一半的参数，我们的模型就能达到与最好的提取器竞争的准确度，而且速度更快。

**前排提示**：这里需要先理解一下作者所提出的**标签空间**是什么意思，原先预测实体和关系的时候都是使用单独的解码器来实现的；也就是说你给我一个候选实体，我来告诉你这个是哪种实体类型（标签空间是实体集合）；你给我一个对实体，我来告诉你他们之间的关系（标签空间是关系集合），这里是举个比较容易理解的例子，不代表所有联合模型的解码步骤哈；那么作者这里的标签空间就是说模型在进行推断的时候是在所有实体和关系集合里面进行选择的，一个格子即可能被预测为实体，也可以被预测为关系，当然可以预测为空；

作者首先阐述自己的动机，即之前[[2010.12812] A Frustratingly Easy Approach for Entity and Relation Extraction (arxiv.org)](https://arxiv.org/abs/2010.12812) 论文中所提到的，独立的标签空间应该使用独立的编码器，不同的编码器会互相冲突。那么作者就认为原先的联合模型不行，虽然使用的是共享的编码器，但是使用的标签空间还是独立的，所以我直接使用联合编码器和联合标签空间不就行了吗，这不就是不会冲突了吗？

作者的关键思想是将实体的检测作为关系检测的一种特例，统一的处理表格中的所有单元格；

![图片](https://xerrors.oss-cn-shanghai.aliyuncs.com/imgs/20210824225843-imagepng)

#### 模型介绍

下面介绍一下模型的做法，模型跟多数填表任务一样，分为编码、填表和解码三步；

![图片](https://xerrors.oss-cn-shanghai.aliyuncs.com/imgs/20210825102103-imagepng)

**编码**

首先模型的输入是先将原始的编码经过类似于 BERT 的预训练模型之后，得到**特征向量**；这里的预训练模型的输入，包括对应位置的 token、位置嵌入、语义嵌入以及利用滑动窗口得到的跨句子上下文嵌入（具体的实现方法还不清楚）；

$$
{\mathbf{h}_1, \dots , \mathbf{h}_{|s|}} = \text{PTM}({\mathbf{x}_1, \dots , \mathbf{x}_{|s|}})

$$

当然了，使用预训练模型进行编码已经是基本操作了，那么下一步，作者就使用了一个双仿射注意力机制进行编码；原理我还不是很清楚（这里插个眼），具体而言就是将远门的特征向量通过两个不同的 MLP 得到 head 和 tail 两个不同的映射表征；然后使用双仿射模型得到分数向量 $\mathbf{g}_{i,j } \in \mathbb{R}^{|\mathcal{Y}|}$；$|\mathcal{Y}|$ 表示所有标签的长度，包括实体标签、关系标签以及空标签；

$$
\begin{aligned}
\mathbf{g}_{i,j} &= \text{Biaff}\left(\text{ MLP}_{\text{head}}\left(\mathbf{h}_{i}\right), \text{ MLP}_{\text{tail}}\left(\mathbf{h}_{i}\right)  \right) \\
\text{Biaff}(\mathbf{h}_1, \mathbf{h}_2) &= \mathbf{h}_1^{T} \mathbf{U}_1 \mathbf{h}_2 + \mathbf{U}_2 ([\mathbf{h}_1;\mathbf{h}_2]) + \mathbf{b}
\end{aligned}

$$

**填表**

填表很好理解，就是把上面得到的分数做一下 softmax 就可以了，不过需要注意的是作者使用了 dropout 函数来增强效果（后面会分析）；

$$
P\left(\mathbf{y}_{i, j} \mid s\right)=\operatorname{Softmax}\left(\text { dropout }\left(\mathbf{g}_{i, j}\right)\right)

$$

填表虽然好理解，但是由于作者是将实体和关系一起预测的，就会出现一些出乎意料的结果，比如实体的标签出现在了非对角线区域且不与对角线的实体标签相连，或者一些对称关系并没有对称的出现在表中，亦或是出现了关系，但是这个关系却没有相对应的实体被预测出来；这些都是可能会出现的问题；为了抑制这些情况的出现，必须使用额外的约束条件作为损失函数来控制整个模型；

为此作者提出了两个约束条件，分别是**对称性约束**（Symmetry）**可能性约束**（Implication）；翻译的可能不对。

对称性约束即对于**一些对称关系**，若实体 1 与实体 2 存在对称的关系 r，那么，实体 2  应该与实体 1 存在此关系，对应在表上的表现就是此关系应该关于对角线对称出现。这里的对称关系是需要手工挑选出来的，并不代表所有的关系，具体的可以看下面的损失函数计算公式，使用的是对称关系的标签集合 $\mathcal{Y}_{sym}$。

关于可能性约束，有个很重要的前提：某个单元格被预测为实体的概率必须要大于该实体存在某个关系的概率。通俗点说，某个单元格有 30% 的概率被预测为实体 A，但是该单元格却有 60% 的概率跟其他实体存在关系 R，这显然是不合理的，必须要能够有把握认为是实体，才能有把握预测出关系啊。

那么结合前面的预测损失、对称性损失、可能性损失；就可以得到最终的损失函数，这里注意 $\mathcal{P} \in \mathbb{R}^{|s| \times|s| \times|\mathcal{Y}|}$ 是上面计算得到的 P 的堆叠，反正 $\mathcal{P}_{i,j,k}$ 表示第 i 个位置和第 j 个位置存在标签 k 的概率。还有一点需要注意的哈，这里的 $y_{i.j}$ 是来自表 T 的，表 T 是根据标签数据来生成的。

$$
\begin{aligned}

\mathcal{L}_{\text {entry }} &=-\frac{1}{|s|^{2}} \sum_{i=1}^{|s|} \sum_{j=1}^{|s|} \log P\left(\mathbf{y}_{i, j}=y_{i, j} \mid s\right) \\

\mathcal{L}_{\mathrm{sym}} &=\frac{1}{|s|^{2}} \sum_{i=1}^{|s|} \sum_{j=1}^{|s|} \sum_{t \in \mathcal{Y}_{\mathrm{sym}}}\left|\mathcal{P}_{i, j, t}-\mathcal{P}_{j, i, t}\right| \\

\mathcal{L}_{\mathrm{imp}} &=\frac{1}{|s|} \sum_{i=1}^{|s|}\left[\max _{l \in \mathcal{Y}_{r}}\left\{\mathcal{P}_{i,:, l}, \mathcal{P}_{:, i, l}\right\}-\max _{t \in \mathcal{Y}_{e}}\left\{\mathcal{P}_{i, i, t}\right\}\right]_{*} \\

\end{aligned}

$$

**解码**

表格是填好了，那么这个表格里面内容表示什么意思呢？这时候就需要使用解码器进行解码，解码的思路也很简单，我们再来回头看一下这个表：

![图片](https://xerrors.oss-cn-shanghai.aliyuncs.com/imgs/20210824225843-imagepng)

对于 wife 这个单词，我们按行来看，wife 的前一行与后一行都跟 wife 这一行差别很大，说明 wife 是一个长度为 1 的跨度，按列看同理；那么对于 David Perkins，可以看到第一行跟第二行是一样的，而第三行跟第二行不一样，列同理；所以可以认为 Darvid Perkins 是个长度为 2 的跨度。总的来说，对于长度为 1 的跨度他所在的行和列跟相邻的行和列的相似度很低，而对于长度大于 1 的跨度，跨度内的相邻行（或列）是一样的，而与边界处的行（或列）差别很大，那么就可以通过比较相邻行的距离来判断跨度；

计算过程如下图所示：

![图片](https://xerrors.oss-cn-shanghai.aliyuncs.com/imgs/20210825115803-imagepng)

首先是**跨度解码**，把 $\mathcal{P}$ 按行和列分别展开，得到两个新的矩阵 $\mathcal{P}^{row}, \mathcal{P}^{col}$；这时候分别计算相邻行的欧氏距离（$l_2$），得到距离之后如果两个距离的平均值大于一个阈值 $\alpha=1.4$ 的时候就认为这是个可能的跨度分界点；如框 1 所示。

第二步就是对**实体解码**，上面已经得到跨度了，那么对于每一个跨度都计算一下是否是实体，$\hat{t}=\arg \max _{t \in \mathcal{Y}_{e} \cup\{\perp\}} \operatorname{Avg}\left(\mathcal{P}_{i: j, i: j, t}\right)$；

第三步就是对**关系解码**，给定两个实体以及两个实体的跨度 $(i,j),(m,n)$；就能计算关系了：$\hat{l}=\arg \max _{l \in \mathcal{Y}_{r} \cup\{\perp\}} \operatorname{Avg}\left(\mathcal{P}_{i: j, m: n, l}\right)$；

这里补充两点疑问，一是这个方法似乎**没法获取重叠的实体和重叠的关系**吧？

#### 实验表现

直接看数据，从数据表现上来看已经取得了比较好的效果，但是似乎还不如 Chen 团队的 PURE 策略，即使在 SciERC 数据集上有所超越，但是效果并不是很明显。

![图片](https://xerrors.oss-cn-shanghai.aliyuncs.com/imgs/20210825123520-imagepng)

除此之外，作者针对自己模型的各个模块做了对比实验，还设计了一个硬解码的方法，实验的细节可以参考原论文 4.2 节，这里主要聊一下实验的结果；

首先是文中在去除可能性损失限制后，在很多指标上都有更好的表现，有时表现在实体上，有时表现在关系上；

![图片](https://xerrors.oss-cn-shanghai.aliyuncs.com/imgs/20210825124309-imagepng)

文中比对了 Dropout 和 跨句子语境之后，认为 dropout 的加入避免了过拟合（存疑），跨句子语境提供了更多的上下文信息，尤其是在 SciERT 这个小数据集上表现更好。

最后是关于硬解码部分，我不是很理解，从实验结果来看，hard decoding 的表现确实很差，作者也认为：“主要原因是 "**硬解码**" 对实体和关系分别进行解码。这表明作者提出的联合解码算法联合考虑了实体和关系，这对解码很重要“。但是从损失函数来看，你这个解码算法并不会在模型的训练过程中存在啊，也即是说不同的解码算法并不影响模型的性能，只是会影响对模型输出的判断啊。

后面关于计算性能的表现没有意义，主要看一下错误分析，模型中出现了很多 “没有找到“ 错误的例子，作者认为主要原因是填表时存在类不平衡问题，即“非关系”的数量远远大于其他类的数量，会今后的研究中处理这个不平衡的分类问题。

**作者结论**：

> 在这项工作中，我们在一个**统一的标签空间**中提取实体和关系，以更好地挖掘这两个子任务之间的互动。我们提出了一个新颖的表格，将实体和关系呈现为正方形和长方形。然后，这个任务可以通过两个简单的步骤完成：用我们的biaffine模型填充表格，用我们的**联合解码算法**对实体和关系进行解码。在三个基准上的实验表明，所提出的方法不仅达到了最先进的性能，而且还具有良好的效率。

**我的结论**：

本文的主要亮点在于填表法的联合解码，虽然效果并不是很好，但是可以看到论文中有很多的超参数会影响到最终的预测效果，所以这个思路目前来看是可行的，但却不是很惊艳的。同样也没法解决实体重叠和关系重叠的问题。
