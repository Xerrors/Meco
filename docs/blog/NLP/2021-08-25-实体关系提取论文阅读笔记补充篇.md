---
title: 实体关系提取论文阅读笔记补充篇
date: 2021-08-25 14:42:07
permalink: /ere-note-expend-1/
cover: 
tags: 
- NLP
- ERE
categories: NLP
---
这篇文章主要是记录自己在阅读实体关系提取的相关论文的简单笔记

## 1. 介绍

论文列表：

- [A Relation-Specific Attention Network for Joint Entity and Relation Extraction (ijcai.org)](https://www.ijcai.org/proceedings/2020/0561.pdf)
- [ Joint Entity and Relation Extraction with Set Prediction Networks (arxiv.org)](https://arxiv.org/abs/2011.01675)
- [Representation iterative fusion based on heterogeneous graph neural network for joint entity and relation extraction - ScienceDirect](https://www.sciencedirect.com/science/article/pii/S0950705121001519)

## 2. 详细记录

这部分会仔细介绍论文的动机以及模型可能存在的问题。

### 基于关系的注意力网络

论文在此：[A Relation-Specific Attention Network for Joint Entity and Relation Extraction (ijcai.org)](https://www.ijcai.org/proceedings/2020/0561.pdf)

先看摘要：

> 实体和关系的联合抽取是自然语言处理(NLP)中的一项重要任务，其目的是从纯文本中获取所有的关系三元组。这是一个很大的挑战，因为从一个句子中提取的一些三元组可能有重叠的实体。现有的大多数方法都是先进行实体识别，然后再检测每个可能的实体对之间的关系，这通常需要进行大量的冗余操作。本文提出了一种**基于关系的注意力网络(RSAN)**来解决这一问题。我们的RSAN利用**关系感知的注意机制**为每个关系构建特定的句子表示，然后进行**序列标注**以提取其对应的头部和尾部实体。在两个公开数据集上的实验表明，我们的模型能够有效地提取重叠的三元组，并取得了最好的性能。我们的代码可以在[github.com/Anery/RSAN](https://github.com/Anery/RSAN)上找到

作者的核心假设在于：**在不同的关系下，词语对句子的底层语义表达应该有不同的贡献**。（虽然这跟后续 PURE 所做的实验并不一致，在此先可以这么认为）

#### 模型介绍

从摘要的加粗部分可以看到，此文作者所提出的模型依然是采用序列标注的方法来预测实体的；但是为了减少冗余，作者是先预测了句子中可能存在的关系，将问题转化为多序列标注问题；

![图片](https://xerrors.oss-cn-shanghai.aliyuncs.com/imgs/20210825190045-imagepng)

下图是整个模型的结构图，图中是以一个关系为例来介绍模型的运算过程。

![图片](https://xerrors.oss-cn-shanghai.aliyuncs.com/imgs/20210825190206-imagepng)

我大致将整个过程分为：句子编码、基于关系的注意力机制、关系门机制、特定关系的实体解码器

**句子编码**

句子编码的输入包括了词嵌入、part-of-speech(POS)以及字符级特征；通过 BiLSTM 之后就可以得到包含上下文信息的特征向量 $\mathbf{h}_i = \operatorname{LSTM}(\mathbf{x}_i)$；

**基于关系对句子加权**

由于核心假设认为**在不同的关系下，词语对句子的底层语义表达应该有不同的贡献**。所以需要针对不同的关系对句子中的单词进行注意力加权，注意力加权的方式如下公式：

$$
\begin{aligned}
\mathbf{s}_{g} &=\operatorname{avg}\left\{\mathbf{h}_{1}, \mathbf{h}_{2}, \ldots, \mathbf{h}_{n}\right\} \\
\mathbf{e}_{i k} &=\mathbf{v}^{T} \tanh \left(\mathbf{W}_{r} \mathbf{r}_{k}+\mathbf{W}_{g} \mathbf{s}_{g}+\mathbf{W}_{h} \mathbf{h}_{i}\right) \\
\alpha_{i k} &=\frac{\exp \left(\mathbf{e}_{i k}\right)}{\sum_{j=1}^{n} \exp \left(\mathbf{e}_{j k}\right)}
\end{aligned}

$$

其中 $\mathbf{s}_g$ 表示句子的全局表征，$\mathbf{r}\in \mathbb{R}^{d_r}$ 是个可学习的嵌入矩阵， $\mathbf{r}_k$ 表示第 $k$ 个关系；$\alpha_{i k}$ 就表示在关系 $k$ 下，第 $i$ 个单词的注意力权重，对句子进行加权求和之后也就得到了**特定的句子表征**。$\mathbf{s}_{k} = \sum_{i=1}^{n} \alpha_{i k} \mathbf{h}_{i}$

**利用关系门机制得到单词的最终表征**

这里需要注意，只有当关系对句子是正向效果的时候才会使用上述关系加权去预测实体，否则会影响后续的实体解码过程；

$$
\begin{aligned}
g_{k} &=\sigma\left(\left(\mathbf{W}_{1} \mathbf{s}_{g}+b_{1}\right) \oplus\left(\mathbf{W}_{2} \mathbf{s}_{k}+b_{2}\right)\right) \\
\mathbf{u}_{\mathbf{k}} &=g_{k} \odot \tanh \left(\mathbf{W}_{3} \mathbf{s}_{k}+b_{3}\right)
\end{aligned}

$$

其中 $g_k$ 是用来衡量原有的句子表示 $\mathbf{s}_g$ 和基于关系的表示 $\mathbf{s}_k$ 哪一个更有利于实体提取。$\mathbf{u_k}$ 则是表示保留下来的关系特征。那么最终的单词表征就是将两者拼接起来：$\mathbf{h}_i^k = \mathbf{h}_i \oplus \mathbf{u_k} $；

不过我有个疑问，这岂不是针对每个关系都去预测实体，如果关系变得很多的话，其实不是很麻烦，应该先过滤一下不太可能存在于这个句子中的关系吧。可以参考这里的关系判断去过滤掉一部分关系：[PRGC: Potential Relation and Global Correspondence Based Joint Relational Triple Extraction (aclanthology.org)](https://aclanthology.org/2021.acl-long.486.pdf)。当然本篇论文是发表于 2020 年的，而 PRGC 是发布于 2021 年的哈哈哈哈。

**实体解码**

因为是序列标注问题，所以解码其实很简单就是 LSTM 加上一个全连接层：

$$
\begin{aligned}
\mathbf{o}_{i}^{k}&= \operatorname{BiLSTM}(\mathbf{h}_i^k)\\
P\left(y_{i}^{k}\right)&=\operatorname{Softmax}\left(\mathbf{W}_{\mathrm{o}} \cdot \mathbf{o}_{\mathrm{i}}^{\mathrm{k}}+\mathbf{b}_{\mathrm{o}}\right)
\end{aligned}

$$

损失函数如下所示：

$$
\mathcal{L}=\frac{1}{n_{s} \times n} \sum_{k=1}^{n_{s}} \sum_{i=1}^{n}-\log P\left(y_{i}^{k}=\hat{y}_{i}^{k}\right)

$$

#### 实验部分

实验效果上的提升还是很可观的：

![图片](https://xerrors.oss-cn-shanghai.aliyuncs.com/imgs/20210825201943-imagepng)

实验只是手段，分析才是重点，总的来说作者认为自己的模型有两点优势：(1) RSAN更关注与关系相关的实体，避免了预测冗余实体对带来的错误；(2) 使用关系感知的实体标注过程能够捕获实体抽取和关系之间的依赖关系。

其中作者认为自己的表现效果超过了之前采用了面向关系的策略的模型，主要是因为 RSAN 的注意力机制包含了细粒度的关系信息，这使得我们能够更明确地指导实体提取过程。（也就是关系门机制的作用）

**作者结论**：

> 本文提出了一种面向联合实体和关系抽取任务的关系关注序列标注框架RSAN。该方法将重叠三元组抽取问题分解为若干个特定关系的实体标注过程，并利用注意力机制融合细粒度关系信息作为实体抽取的指导。在NYT和WebNLG语料库上的实验表明，我们提出的RSAN模型取得了显著的改进。扩展实验证明了RSAN在处理重叠和多个三元组提取场景时的有效性。

**我的结论**：

本文最大的亮点就在于利用关系去预测实体的想法，并通过关系门来控制关系对句子的影响（不知道是不是首创），但是起码效果上来看还是不错的，不过我还是比较担心当关系变多的时候的运算效率问题。

### 集合预测网络

论文在此：[[2011.01675] Joint Entity and Relation Extraction with Set Prediction Networks (arxiv.org)](https://arxiv.org/abs/2011.01675)

话不多说，先看摘要：

> 实体和关系的联合提取任务旨在从一个句子中提取所有的关系三元组。从本质上讲，**一个句子中包含的关系三元组是无序的**。然而，以前基于seq2seq的模型需要在训练阶段将三元组的集合转换为一个序列。为了打破这一瓶颈，我们将实体和关系的联合提取视为一个直接的集合预测问题，这样提取模型就可以摆脱预测多个三要素的顺序的负担。为了解决这个集合预测问题，我们提出了以具有**非自回归并行解码**的 Transformer 为特征的网络。与按一定顺序逐个生成三元组的自回归方法不同，我们提出的网络直接一次性输出最终的三元组集合。此外，我们还设计了一种基于集合的损失，通过双侧匹配（bipartite matching）强制进行唯一的预测。与交叉熵损失（高度惩罚三元组顺序的微小变化）相比，所提出的**双联体匹配损失**对任何预测的排列组合都是不变的；因此，它可以通过忽略三联体顺序和关注关系类型和实体为所提出的网络提供更准确的训练信号。在两个基准数据集上的实验表明，我们提出的模型明显优于目前最先进的方法。训练代码和训练后的模型将在 http://github.com/DianboWork/SPN4RE。

核心思想：**一个句子中包含的关系三元组是无序的**；所以需要设计新的一体网路，设计一个忽略三元组顺序的新损失函数；

文章的主要工作在于**非自回归的解码器**和顺序无关的**损失函数**；

#### 模型介绍

首先是**解码器**，作者认为非自回归解码与之前基于 seq2seq 的方法相比，非自回归解码器不仅可以避免学习多个三元组的提取顺序，而且可以基于双向信息生成三元组，而不仅仅是从左到右的信息。

$$
\begin{aligned}
P(Y \mid X ; \theta) &= p_{L}(n \mid X) \prod_{i=1}^{n} p\left(Y_{i} \mid X, Y_{j \neq i} ; \theta\right) \\
P(Y \mid X ; \theta) &= \prod_{i=1}^{n} p\left(Y_{i} \mid X, Y_{j \lt i} ; \theta\right)
\end{aligned}

$$

对应到公式，上面是非自回归解码的条件概率公式，下面是 seq2seq 自回归解码的条件概率公式。（我认识可能是因为 seq2seq 是按照顺序生成的）其中 $p_{L}(n \mid X)$ 代表目标三元组集合的大小，作者最后选择将其作为一个常数 $m$ 来表示，对应到下图就是 $m=4$；

![图片](https://xerrors.oss-cn-shanghai.aliyuncs.com/imgs/20210830143548-imagepng)

解码器的输入就是 $m$ 个预设三元组的嵌入，这是个全局共享且可以学习的参数，关于解码器的介绍如下：

> 非自回归解码器是由N个相同的转换层堆叠而成的。在每个转换层中，都有**多头自注意力机制**（Multi-Head Self-Attention）来模拟三要素之间的关系，以及**多头相互注意力机制**（Multi-Head Inter-Attention）来融合给定句子的信息。值得注意的是，与自回归解码器相比，**非自回归解码器没有输出的自回归因子的约束**，所以不需要防止早期解码步骤从后面的步骤中获取信息。因此，在多头自我关注机制中没有使用随意掩码。相反，我们使用的是无掩码的自我注意。（即上述公式中所表示的 $i \ne j$ 吗？）

那么之后就是通过前馈网络得到最终结果了。$\mathbf{H}_{d}^{l} \in \mathbb{R}^{m \times d}$ 表示第 $l$ 层解码器的输出，$\mathbf{H}_e \in \mathbb{R} ^ {n \times d}$ 表示句子编码器的输出，图中左侧部分。

$$
\mathbf{H}_{d}^{l} = \operatorname{Decoder} (\mathbf{H}_{l-1}, \mathbf{H}_e)

$$

之后就是对第 N 层的输出做预测了，其中 $\mathbf{h}_d$ 是 $\mathbf{H}_{d}^{N}$ 的元素，$\mathbf{W}$ 和 $\mathbf{v}_i$ 都是可学习的参数；

$$
\mathbf{p}^{r}=\operatorname{softmax}\left(\mathbf{W}_{\mathbf{r}} \mathbf{h}_{\mathrm{d}}\right)

$$

与此同时预测实体的位置，这两个步骤是并行的，这大概就是摘要中作者提到的并行解码吧；

$$
\begin{aligned}
\mathbf{p}^{s-\text { start }} &=\operatorname{softmax}\left(\mathbf{v}_{\mathbf{1}}^{\mathbf{T}} \tanh \left(\mathbf{W}_{\mathbf{1}} \mathbf{h}_{\mathrm{d}}+\mathbf{W}_{\mathbf{2}} \mathbf{H}_{\mathbf{e}}\right)\right) \\
\mathbf{p}^{s-e n d} &=\operatorname{softmax}\left(\mathbf{v}_{\mathbf{2}}^{\mathbf{T}} \tanh \left(\mathbf{W}_{\mathbf{3}} \mathbf{h}_{\mathbf{d}}+\mathbf{W}_{\mathbf{4}} \mathbf{H}_{\mathbf{e}}\right)\right) \\
\mathbf{p}^{o-\text { start }} &=\operatorname{softmax}\left(\mathbf{v}_{\mathbf{3}}^{\mathbf{T}} \tanh \left(\mathbf{W}_{\mathbf{5}} \mathbf{h}_{\mathbf{d}}+\mathbf{W}_{\mathbf{6}} \mathbf{H}_{\mathbf{e}}\right)\right) \\
\mathbf{p}^{o-e n d} &=\operatorname{softmax}\left(\mathbf{v}_{\mathbf{4}}^{\mathbf{T}} \tanh \left(\mathbf{W}_{\mathbf{7}} \mathbf{h}_{\mathrm{d}}+\mathbf{W}_{\mathbf{8}} \mathbf{H}_{\mathbf{e}}\right)\right)
\end{aligned}

$$

由此也就得到了模型的输出了，用 $\{ \hat{\mathbf{Y}}_i = (\mathbf{p}_i^{r}, \mathbf{p}_i^{s-start}, \mathbf{p}_i^{s-end}, \mathbf{p}_i^{o-start}, \mathbf{p}_i^{o-end}) \} _{i=1} ^ {m}$ 表示；接下来就把标签数据 $\mathbf{Y}=\left\{\mathbf{Y}_{i}\right\}_{i=1}^{n}$ 使用 $\varnothing$ 填充到 $m$ 长度。这样就可以比较两者之间的差距并计算损失了。

编码器大致还算能够了解的话，接下来就开始计算损失了；我们想一下，一个句子里面存在的这些关系跟预测出来的这些关系的顺序是不一样的，应该怎么解决。在之前的模型中（好问题，之前的 seq2seq 模型都是怎么算的，我似乎还没读过其他的 seq2seq 模型）；反正这里就是先把所有的 $m$ 个预测的三元组进行全排列，之后针对每一个组合方式（$\pi$）都跟标注数据（$\mathbf{Y}$）计算一下代价，然后找到代价最小的那个组合。那么实际上这个代价最小的这个组合 $\pi^{\star}$。

$$
\pi^{\star}=\underset{\pi \in \Pi(m)}{\arg \min } \sum_{i=1}^{m} \mathcal{C}_{\text {match }}\left(\mathbf{Y}_{i}, \hat{\mathbf{Y}}_{\pi(i)}\right)

$$

其中，这个 $\mathcal{C}_{\text {match }}$ 定义如下，这里是使用的匈牙利算法来计算的，具体的还是参考原论文的附录吧，我看的要不是很明白；如果实在看不懂，跟我一样不管了，这就是为了计算一个代价而已。

$$
\begin{aligned}
\mathcal{C}_{\text {match }}\left(\mathbf{Y}_{i}, \hat{\mathbf{Y}}_{\pi(i)}\right) &=-\mathbb{1}_{\left\{r_{i} \neq \varnothing\right\}}\left[\mathbf{p}_{\pi(i)}^{r}\left(r_{i}\right)\right.\\
&+\mathbf{p}_{\pi(i)}^{s-start}\left(s_{i}^{\text {start }}\right) + \mathbf{p}_{\pi(i)}^{s-end}\left(s_{i}^{end}\right) \\
&+\mathbf{p}_{\pi(i)}^{o-start}\left(o_{i}^{\text {start }}\right)\left . + \mathbf{p}_{\pi(i)}^{o-end}\left(o_{i}^{end}\right)\right]
\end{aligned}

$$

这里注意，上面只是得到了一个代价最小的组合，跟最终的损失还是不一样的，所以还需要针对上面的组合 $\pi^{\star}$ 来计算一下最终的损失。

$$
\begin{aligned}
\mathcal{L}(\mathbf{Y}, \hat{\mathbf{Y}}) &=\sum_{i=1}^{m}\left\{-\log \mathbf{p}_{\pi^{\star}(i)}^{r}\left(r_{i}\right)\right.\\
&+\mathbb{1}_{\left\{r_{i} \neq \varnothing\right\}}\left[-\log \mathbf{p}_{\pi^{\star}(i)}^{s-s t a r t}\left(s_{i}^{\text {start }}\right)\right.\\
&-\log \mathbf{p}_{\pi^{\star}(i)}^{s-e n d}\left(s_{i}^{\text {end }}\right) \\
&-\log \mathbf{p}_{\pi^{\star}(i)}^{o-\text { start }}\left(o_{i}^{\text {start }}\right) \\
&\left.\left.-\log \mathbf{p}_{\pi^{\star}(i)}^{o-e n d}\left(o_{i}^{\text {end }}\right)\right]\right\}
\end{aligned}

$$

然后论文在此戛然而止，就没了，这就是前面所提到的**双联体匹配损失**（bipartite matching loss）我是没看懂。

#### 实验结果

这实验数据还能说啥，到现在还是榜一呢。

![图片](https://xerrors.oss-cn-shanghai.aliyuncs.com/imgs/20210830183405-imagepng)

这是重点看一下这个模型的实验结果有没有能够验证自己的思路和想法，所以首先应该是对比实验；右表是关于解码器和损失函数之间的实验结果；

![图片](https://xerrors.oss-cn-shanghai.aliyuncs.com/imgs/20210830183823-imagepng)

可以看到使用交叉熵损失函数之后效果相对而言，降低了 8.5%；证明了这个损失函数的有效性。不过我觉得这里通过增加解码器层数的方法并不是很有说服力；倒是如下图所示，当 N=1 的时候，此时 Biaprtite Matching Loss 是没有作用的（是的吧），这个非自回归的模型的表现依然是比之前的 SOTA 要好。

![图片](https://xerrors.oss-cn-shanghai.aliyuncs.com/imgs/20210830184512-imagepng)

除此之外，作者还做了一个有趣的实验，如图所示，横着来看， SPN 的 Precision 和 Recall 更加均匀，作者认为是因为在训练的时候自己的 m 的设置的要比句子中的三元组数目要多。

此外，在 WebNLG 里，实体识别和关系提取的结果都比联合提取任务要高，作者认为这意味着实体对抽取和关系类型抽取的准确结合是提高联合实体和关系抽取的关键。

那为啥 NYT 和 WebNLG 有区别呢？区别就是在于 WebNLG 的 SEO 比较多。

![图片](https://xerrors.oss-cn-shanghai.aliyuncs.com/imgs/20210830184823-imagepng)

作者总结：

> 在本文中，我们介绍了用于联合实体和关系提取的集合预测网络。与以往基于seq2seq的模型相比，我们将实体和关系的联合提取任务表述为一个集合预测问题。这样一来，提取模型就可以不必预测多个三元组的提取顺序了。为了解决集合预测问题，我们将非自回归并行解码与双点匹配损失函数相结合。我们在两个广泛使用的数据集上进行了广泛的实验来验证所提出的集合预测网络的有效性。实验结果表明，我们提出的网络在不同场景下的表现优于最先进的基线。这项具有挑战性的任务还远远没有得到解决。我们发现，**关系类型在NYT数据集和WebNLG数据集中表现出不平衡或长尾分布**。我们未来的工作将集中在如何将成本敏感的学习与所提出的集合预测网络相结合。

我的总结：

从作者的实现想法来看，这里的 bipartite matching loss 已经印证了作者的想法；不过我并不清楚是因为和非自回归编码一起使用所导致的。这个值得思考，但作者又没做实验，那就不得而知了。

有一说一，作者在附录里面详细的介绍了匈牙利算法以及 bipartite matching loss 的计算方法。Good！

### 基于异构图神经网络的表征迭代融合

论文在此：[Representation iterative fusion based on heterogeneous graph neural network for joint entity and relation extraction - ScienceDirect](https://www.sciencedirect.com/science/article/pii/S0950705121001519)

有一说一，这名字是真的拗口，读起来很费劲；不过这篇文章是发布在《Knowledge-Based System》，似乎目前是 Sci 一区，不错的。看知乎上说，这个期刊对实验要求很高，我看完这个论文之后确实是真正理解到了；当然也正因如此，这篇论文关于模型和实验的介绍都很充分，尤其是对于我这种对实验接触还不是很多的新手而言，详尽的实验以及对实验结果的分析是非常有帮助的；其次这里的公式也很详细，比 CasRel 这篇论文介绍的详细多了，由于提取方法相似，所以完全可以通过这篇论文来理解 CasRel 的详细提取办法。

话不多说，还是先看摘要：

> 实体和关系的联合提取是信息提取中的一项重要任务，其目的是为了从非结构化文本中提取所有的关系三元组。然而，**现有的工作在提取实体之前很少考虑实体之间可能存在的关系信息，这可能导致大部分提取的实体不能构成有效的三联体**。在本文中，我们提出了一种基于异构图神经网络的关系提取的表示法迭代融合（RIFRE）。我们将关系和词建模为图上的节点，并通过**消息传递机制**反复融合这两类语义节点，以获得更适合关系提取任务的节点表示。该模型在节点表示被更新后执行关系提取。我们在两个公共关系提取数据集上评估了RIFRE。NYT和WebNLG。结果表明，RIFRE可以有效地提取三元组，并达到最先进的性能。此外，RIFRE也适用于关系分类任务，并在SemEval 2010 Task 8数据集上明显优于以前的方法。

这篇文章的核心其实就在于增强单词和关系表征之间的联系；我们回忆一下大佬的 CasRel，直接把原始输出经过一个 BERT 之后就算是编码结束了。

![图片](https://xerrors.oss-cn-shanghai.aliyuncs.com/imgs/20210907224518-image.png)

所以这次就把每个单词和每个关系当成节点，使用图神经网络来更新每个节点的特征表示。从结构图和提取步骤来看跟 CasRel 的相似度还是很高的，接下来就详细介绍以下这个优秀的模型吧。

1. ![图片](https://xerrors.oss-cn-shanghai.aliyuncs.com/imgs/20210907225023-image.png)

#### 模型介绍

我们肯定是要带着问题去看论文的，当我们第一遍浏览完标题、摘要、图、数据表的时候，我们一定是对这个论文有了一些了解，同时对于其中一些细节并不是很理解，甚至是有点疑惑的。就比如这个神乎其神的 message passing mechanism 是什么东西？这个模型看起来跟 CasRel 很相似啊，尤其是后边的关系提取部分，那么他们的不同点又是哪些呢？

先就着上面这个结构图来说一下整个论文的计算方法；首先是对于句子中的每个单词进行编码（BERT Encoder），对所有的关系进行关系嵌入（Relation Embedding），这样就得到了图结构的初始节点（词节点、关系节点）；

> 注：这里对于关系进行编码的部分，每预测一个句子就需要进行一次编码；同时需要注意对关系进行编码的时候使用的不是 BERT 模型，而是类似与全连接一样的计算方法，毕竟这些关系也不算是一个句子吧；
>
> $\left[\mathbf{r}_{1}, \mathbf{r}_{2}, \ldots, \mathbf{r}_{M}\right]=\mathbf{W}_{r} \mathbf{E}\left(\left[r_{1}, r_{2}, \ldots, r_{M}\right]\right)+\mathbf{b}_{r}$
>
> 这里的 $W_r$ 是个可训练的参数，但是 $\mathbf{E}$ 是一个关系嵌入矩阵，但是这个矩阵是怎么来的并没说，有空去看看代码是怎么实现的吧。

之后就是把这些节点都放在了一个叫 Heterogeneous Graph Layer 的网络层，之后经过一顿操作猛如虎之后每个节点都或多或少的与其他节点有了表征交流（暂且这么理解，后面会介绍），之后就是利用这些节点去预测主语了，预测主语的方法跟 CasRel 非常的相似。当识别到 subject 之后，对于每一个 subject 、每一个关系节点 $\mathbf{r}_j$  拼接上单词节点 $\mathbf{h}_i$ 之后做二分类就得到了宾语的起止坐标。

> 注：其实很多人就指出这里是不是可能会存在问题啊，在预测实体的时候虽然是使用了 start 向量和 end 向量，但是在标注实体的时候是按照最近的尾部节点来匹配实体的，其实对于存在实体重叠问题的任务而言是有一些缺陷的，就比如是没有办法同时匹配到 “北京”、“北京大学”，这两个实体；当然想要解决这个问题可以参考百度的 [TPLinker](https://arxiv.org/abs/2010.13415) ，这里使用牵手的方法匹配实体，自然就解决了重叠实体的问题，但是因为这种类型在数据集中存在的很少，却需要很大的计算开销来解决，所以需要酌情考虑。

作者还添加了一个关系提取任务的损失函数，是直接将主语、宾语和关系节点拼接之后经过一个 MLP 得到最终的结果。

**注**：原文中关于这里计算方法的描述非常详细，所以还是尽量去看一下原文的公式来理解这一部分代码。

**Heterogeneous Graph Layer**

这个模块可以说是整个作者的核心创新模块，其主要作用就是加强单词与关系之间的联系。作者说这个模块的实现是类似于图注意力网络的（GAT）；首先给定两个类型的特征向量 $\left\{\mathbf{u}_{i}\right\}_{i=1}^{N}$ 和 $\left\{\mathbf{v}_{j}\right\}_{j=1}^{M}$；假设他们两个类型之间是互连接的，即任意一个 $\mathbf{u}$ 的邻居是所有的 $\mathbf{v}$ 节点。首先是计算出对于 $\mathbf{u}_i$ 的每个邻居节点 $\mathbf{v}_j$ 的注意力权重，之后按照权重加权求和之后加到节点 $\mathbf{u}_i$ 上。

![图片](https://xerrors.oss-cn-shanghai.aliyuncs.com/imgs/20210908104026-image.png)

其次，作者还加了一个门机制而不是激活函数来更新节点的值，总的而言，上面这个过程就可以认为是这个异构图神经网络的计算过程了；$\tilde{\mathbf{u}}_{i}=\mathbf{G N N}(\mathbf{u}_{i},\{\mathbf{v}_{j}\}_{j \in \mathcal{N}_{i}})$

后面关于更新过程就没什么可说的了，大致就是迭代嘛！

$$
\begin{gathered}
\tilde{\mathbf{h}}_{i}^{l+1}=\mathbf{G N N}\left(\mathbf{h}_{i}^{l},\left\{\mathbf{r}_{j}^{l}\right\}_{j \in \mathcal{N}_{i}}\right) ; 
\mathbf{h}_{i}^{l+1}=\tilde{\mathbf{h}}_{i}^{l+1}+\mathbf{h}_{i}^{l} \\
\tilde{\mathbf{r}}_{j}^{l+1}=\mathbf{G N N}\left(\mathbf{r}_{j}^{l},\left\{\mathbf{h}_{i}^{l+1}\right\}_{i \in \mathcal{N}_{j}}\right) ;
\mathbf{r}_{j}^{l+1}=\tilde{\mathbf{r}}_{j}^{l+1}+\mathbf{r}_{j}^{l}
\end{gathered}

$$

#### 实验结果

实验结果虽然对比了不少模型，但是我们都知道在 CasRel 之前模型的效果都是很差的，所以主要截取他们两个的实验结果，第一个是原始论文的效果，第二是作者复现的，第三个是作者没有使用节点更新机制得到的：

![图片](https://xerrors.oss-cn-shanghai.aliyuncs.com/imgs/20210908104632-image.png)

![图片](https://xerrors.oss-cn-shanghai.aliyuncs.com/imgs/20210908104805-image.png)

我们结合这两张表来看一下，$\operatorname{RIFRE}_{\empty}$ 的效果是 91.6 与 CasRel 的效果接近，也就印证了作者的核心创新是在这里的节点更新上面。那么目的也就达到了hhhhhh。

其实作者做了很多的实验，可以详细的看一下。

比如这里的关系聚类，可以发现作者的方法可以很好的学习到不同关系之间的联系：

![图片](https://xerrors.oss-cn-shanghai.aliyuncs.com/imgs/20210908105237-image.png)
