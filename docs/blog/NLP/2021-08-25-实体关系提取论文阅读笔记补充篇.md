---
title: 实体关系提取论文阅读笔记补充篇
date: 2021-08-25 14:42:07
permalink: /ere-note-expend-1/
cover: 
tags: 
- NLP
- ERE
categories: NLP
---
这篇文章主要是记录自己在阅读实体关系提取的相关论文的简单笔记

## 1. 介绍

论文列表：

- [A Relation-Specific Attention Network for Joint Entity and Relation Extraction (ijcai.org)](https://www.ijcai.org/proceedings/2020/0561.pdf)
- [ Joint Entity and Relation Extraction with Set Prediction Networks (arxiv.org)](https://arxiv.org/abs/2011.01675)
- [Representation iterative fusion based on heterogeneous graph neural network for joint entity and relation extraction - ScienceDirect](https://www.sciencedirect.com/science/article/pii/S0950705121001519)

## 2. 详细记录

这部分会仔细介绍论文的动机以及模型可能存在的问题。

### 基于关系的注意力网络

论文在此：[A Relation-Specific Attention Network for Joint Entity and Relation Extraction (ijcai.org)](https://www.ijcai.org/proceedings/2020/0561.pdf)

先看摘要：

> 实体和关系的联合抽取是自然语言处理(NLP)中的一项重要任务，其目的是从纯文本中获取所有的关系三元组。这是一个很大的挑战，因为从一个句子中提取的一些三元组可能有重叠的实体。现有的大多数方法都是先进行实体识别，然后再检测每个可能的实体对之间的关系，这通常需要进行大量的冗余操作。本文提出了一种**基于关系的注意力网络(RSAN)**来解决这一问题。我们的RSAN利用**关系感知的注意机制**为每个关系构建特定的句子表示，然后进行**序列标注**以提取其对应的头部和尾部实体。在两个公开数据集上的实验表明，我们的模型能够有效地提取重叠的三元组，并取得了最好的性能。我们的代码可以在[github.com/Anery/RSAN](https://github.com/Anery/RSAN)上找到

作者的核心假设在于：**在不同的关系下，词语对句子的底层语义表达应该有不同的贡献**。（虽然这跟后续 PURE 所做的实验并不一致，在此先可以这么认为）

#### 模型介绍

从摘要的加粗部分可以看到，此文作者所提出的模型依然是采用序列标注的方法来预测实体的；但是为了减少冗余，作者是先预测了句子中可能存在的关系，将问题转化为多序列标注问题；

![图片](https://xerrors.oss-cn-shanghai.aliyuncs.com/imgs/20210825190045-imagepng)

下图是整个模型的结构图，图中是以一个关系为例来介绍模型的运算过程。

![图片](https://xerrors.oss-cn-shanghai.aliyuncs.com/imgs/20210825190206-imagepng)

我大致将整个过程分为：句子编码、基于关系的注意力机制、关系门机制、特定关系的实体解码器

**句子编码**

句子编码的输入包括了词嵌入、part-of-speech(POS)以及字符级特征；通过 BiLSTM 之后就可以得到包含上下文信息的特征向量 $\mathbf{h}_i = \operatorname{LSTM}(\mathbf{x}_i)$；

**基于关系对句子加权**

由于核心假设认为**在不同的关系下，词语对句子的底层语义表达应该有不同的贡献**。所以需要针对不同的关系对句子中的单词进行注意力加权，注意力加权的方式如下公式：

$$
\begin{aligned}
\mathbf{s}_{g} &=\operatorname{avg}\left\{\mathbf{h}_{1}, \mathbf{h}_{2}, \ldots, \mathbf{h}_{n}\right\} \\
\mathbf{e}_{i k} &=\mathbf{v}^{T} \tanh \left(\mathbf{W}_{r} \mathbf{r}_{k}+\mathbf{W}_{g} \mathbf{s}_{g}+\mathbf{W}_{h} \mathbf{h}_{i}\right) \\
\alpha_{i k} &=\frac{\exp \left(\mathbf{e}_{i k}\right)}{\sum_{j=1}^{n} \exp \left(\mathbf{e}_{j k}\right)}
\end{aligned}

$$

其中 $\mathbf{s}_g$ 表示句子的全局表征，$\mathbf{r}\in \mathbb{R}^{d_r}$ 是个可学习的嵌入矩阵， $\mathbf{r}_k$ 表示第 $k$ 个关系；$\alpha_{i k}$ 就表示在关系 $k$ 下，第 $i$ 个单词的注意力权重，对句子进行加权求和之后也就得到了**特定的句子表征**。$\mathbf{s}_{k} = \sum_{i=1}^{n} \alpha_{i k} \mathbf{h}_{i}$

**利用关系门机制得到单词的最终表征**

这里需要注意，只有当关系对句子是正向效果的时候才会使用上述关系加权去预测实体，否则会影响后续的实体解码过程；

$$
\begin{aligned}
g_{k} &=\sigma\left(\left(\mathbf{W}_{1} \mathbf{s}_{g}+b_{1}\right) \oplus\left(\mathbf{W}_{2} \mathbf{s}_{k}+b_{2}\right)\right) \\
\mathbf{u}_{\mathbf{k}} &=g_{k} \odot \tanh \left(\mathbf{W}_{3} \mathbf{s}_{k}+b_{3}\right)
\end{aligned}

$$

其中 $g_k$ 是用来衡量原有的句子表示 $\mathbf{s}_g$ 和基于关系的表示 $\mathbf{s}_k$ 哪一个更有利于实体提取。$\mathbf{u_k}$ 则是表示保留下来的关系特征。那么最终的单词表征就是将两者拼接起来：$\mathbf{h}_i^k = \mathbf{h}_i \oplus \mathbf{u_k} $；

不过我有个疑问，这岂不是针对每个关系都去预测实体，如果关系变得很多的话，其实不是很麻烦，应该先过滤一下不太可能存在于这个句子中的关系吧。可以参考这里的关系判断去过滤掉一部分关系：[PRGC: Potential Relation and Global Correspondence Based Joint Relational Triple Extraction (aclanthology.org)](https://aclanthology.org/2021.acl-long.486.pdf)。当然本篇论文是发表于 2020 年的，而 PRGC 是发布于 2021 年的哈哈哈哈。

**实体解码**

因为是序列标注问题，所以解码其实很简单就是 LSTM 加上一个全连接层：

$$
\begin{aligned}
\mathbf{o}_{i}^{k}&= \operatorname{BiLSTM}(\mathbf{h}_i^k)\\
P\left(y_{i}^{k}\right)&=\operatorname{Softmax}\left(\mathbf{W}_{\mathrm{o}} \cdot \mathbf{o}_{\mathrm{i}}^{\mathrm{k}}+\mathbf{b}_{\mathrm{o}}\right)
\end{aligned}

$$

损失函数如下所示：

$$
\mathcal{L}=\frac{1}{n_{s} \times n} \sum_{k=1}^{n_{s}} \sum_{i=1}^{n}-\log P\left(y_{i}^{k}=\hat{y}_{i}^{k}\right)

$$

#### 实验部分

实验效果上的提升还是很可观的：

![图片](https://xerrors.oss-cn-shanghai.aliyuncs.com/imgs/20210825201943-imagepng)

实验只是手段，分析才是重点，总的来说作者认为自己的模型有两点优势：(1) RSAN更关注与关系相关的实体，避免了预测冗余实体对带来的错误；(2) 使用关系感知的实体标注过程能够捕获实体抽取和关系之间的依赖关系。

其中作者认为自己的表现效果超过了之前采用了面向关系的策略的模型，主要是因为 RSAN 的注意力机制包含了细粒度的关系信息，这使得我们能够更明确地指导实体提取过程。（也就是关系门机制的作用）

**作者结论**：

> 本文提出了一种面向联合实体和关系抽取任务的关系关注序列标注框架RSAN。该方法将重叠三元组抽取问题分解为若干个特定关系的实体标注过程，并利用注意力机制融合细粒度关系信息作为实体抽取的指导。在NYT和WebNLG语料库上的实验表明，我们提出的RSAN模型取得了显著的改进。扩展实验证明了RSAN在处理重叠和多个三元组提取场景时的有效性。

**我的结论**：

本文最大的亮点就在于利用关系去预测实体的想法，并通过关系门来控制关系对句子的影响（不知道是不是首创），但是起码效果上来看还是不错的，不过我还是比较担心当关系变多的时候的运算效率问题。

### 集合预测网络

论文在此：[[2011.01675] Joint Entity and Relation Extraction with Set Prediction Networks (arxiv.org)](https://arxiv.org/abs/2011.01675)

话不多说，先看摘要：

> 实体和关系的联合提取任务旨在从一个句子中提取所有的关系三元组。从本质上讲，**一个句子中包含的关系三元组是无序的**。然而，以前基于seq2seq的模型需要在训练阶段将三元组的集合转换为一个序列。为了打破这一瓶颈，我们将实体和关系的联合提取视为一个直接的集合预测问题，这样提取模型就可以摆脱预测多个三要素的顺序的负担。为了解决这个集合预测问题，我们提出了以具有**非自回归并行解码**的 Transformer 为特征的网络。与按一定顺序逐个生成三元组的自回归方法不同，我们提出的网络直接一次性输出最终的三元组集合。此外，我们还设计了一种基于集合的损失，通过双侧匹配（bipartite matching）强制进行唯一的预测。与交叉熵损失（高度惩罚三元组顺序的微小变化）相比，所提出的**双联体匹配损失**对任何预测的排列组合都是不变的；因此，它可以通过忽略三联体顺序和关注关系类型和实体为所提出的网络提供更准确的训练信号。在两个基准数据集上的实验表明，我们提出的模型明显优于目前最先进的方法。训练代码和训练后的模型将在 http://github.com/DianboWork/SPN4RE。

核心思想：**一个句子中包含的关系三元组是无序的**；所以需要设计新的一体网路，设计一个忽略三元组顺序的新损失函数；

文章的主要工作在于**非自回归的解码器**和顺序无关的**损失函数**；

#### 模型介绍

首先是**解码器**，作者认为非自回归解码与之前基于 seq2seq 的方法相比，非自回归解码器不仅可以避免学习多个三元组的提取顺序，而且可以基于双向信息生成三元组，而不仅仅是从左到右的信息。

$$
\begin{aligned}
P(Y \mid X ; \theta) &= p_{L}(n \mid X) \prod_{i=1}^{n} p\left(Y_{i} \mid X, Y_{j \neq i} ; \theta\right) \\
P(Y \mid X ; \theta) &= \prod_{i=1}^{n} p\left(Y_{i} \mid X, Y_{j \lt i} ; \theta\right)
\end{aligned}

$$

对应到公式，上面是非自回归解码的条件概率公式，下面是 seq2seq 自回归解码的条件概率公式。（我认识可能是因为 seq2seq 是按照顺序生成的）其中 $p_{L}(n \mid X)$ 代表目标三元组集合的大小，作者最后选择将其作为一个常数 $m$ 来表示，对应到下图就是 $m=4$；

![图片](https://xerrors.oss-cn-shanghai.aliyuncs.com/imgs/20210830143548-imagepng)

解码器的输入就是 $m$ 个预设三元组的嵌入，这是个全局共享且可以学习的参数，关于解码器的介绍如下：

> 非自回归解码器是由N个相同的转换层堆叠而成的。在每个转换层中，都有**多头自注意力机制**（Multi-Head Self-Attention）来模拟三要素之间的关系，以及**多头相互注意力机制**（Multi-Head Inter-Attention）来融合给定句子的信息。值得注意的是，与自回归解码器相比，**非自回归解码器没有输出的自回归因子的约束**，所以不需要防止早期解码步骤从后面的步骤中获取信息。因此，在多头自我关注机制中没有使用随意掩码。相反，我们使用的是无掩码的自我注意。（即上述公式中所表示的 $i \ne j$ 吗？）

那么之后就是通过前馈网络得到最终结果了。$\mathbf{H}_{d}^{l} \in \mathbb{R}^{m \times d}$ 表示第 $l$ 层解码器的输出，$\mathbf{H}_e \in \mathbb{R} ^ {n \times d}$ 表示句子编码器的输出，图中左侧部分。

$$
\mathbf{H}_{d}^{l} = \operatorname{Decoder} (\mathbf{H}_{l-1}, \mathbf{H}_e)

$$

之后就是对第 N 层的输出做预测了，其中 $\mathbf{h}_d$ 是 $\mathbf{H}_{d}^{N}$ 的元素，$\mathbf{W}$ 和 $\mathbf{v}_i$ 都是可学习的参数；

$$
\mathbf{p}^{r}=\operatorname{softmax}\left(\mathbf{W}_{\mathbf{r}} \mathbf{h}_{\mathrm{d}}\right)

$$

与此同时预测实体的位置，这两个步骤是并行的，这大概就是摘要中作者提到的并行解码吧；

$$
\begin{aligned}
\mathbf{p}^{s-\text { start }} &=\operatorname{softmax}\left(\mathbf{v}_{\mathbf{1}}^{\mathbf{T}} \tanh \left(\mathbf{W}_{\mathbf{1}} \mathbf{h}_{\mathrm{d}}+\mathbf{W}_{\mathbf{2}} \mathbf{H}_{\mathbf{e}}\right)\right) \\
\mathbf{p}^{s-e n d} &=\operatorname{softmax}\left(\mathbf{v}_{\mathbf{2}}^{\mathbf{T}} \tanh \left(\mathbf{W}_{\mathbf{3}} \mathbf{h}_{\mathbf{d}}+\mathbf{W}_{\mathbf{4}} \mathbf{H}_{\mathbf{e}}\right)\right) \\
\mathbf{p}^{o-\text { start }} &=\operatorname{softmax}\left(\mathbf{v}_{\mathbf{3}}^{\mathbf{T}} \tanh \left(\mathbf{W}_{\mathbf{5}} \mathbf{h}_{\mathbf{d}}+\mathbf{W}_{\mathbf{6}} \mathbf{H}_{\mathbf{e}}\right)\right) \\
\mathbf{p}^{o-e n d} &=\operatorname{softmax}\left(\mathbf{v}_{\mathbf{4}}^{\mathbf{T}} \tanh \left(\mathbf{W}_{\mathbf{7}} \mathbf{h}_{\mathrm{d}}+\mathbf{W}_{\mathbf{8}} \mathbf{H}_{\mathbf{e}}\right)\right)
\end{aligned}

$$

由此也就得到了模型的输出了，用 $\{ \hat{\mathbf{Y}}_i = (\mathbf{p}_i^{r}, \mathbf{p}_i^{s-start}, \mathbf{p}_i^{s-end}, \mathbf{p}_i^{o-start}, \mathbf{p}_i^{o-end}) \} _{i=1} ^ {m}$ 表示；接下来就把标签数据 $\mathbf{Y}=\left\{\mathbf{Y}_{i}\right\}_{i=1}^{n}$ 使用 $\varnothing$ 填充到 $m$ 长度。这样就可以比较两者之间的差距并计算损失了。

编码器大致还算能够了解的话，接下来就开始计算损失了；我们想一下，一个句子里面存在的这些关系跟预测出来的这些关系的顺序是不一样的，应该怎么解决。在之前的模型中（好问题，之前的 seq2seq 模型都是怎么算的，我似乎还没读过其他的 seq2seq 模型）；反正这里就是先把所有的 $m$ 个预测的三元组进行全排列，之后针对每一个组合方式（$\pi$）都跟标注数据（$\mathbf{Y}$）计算一下代价，然后找到代价最小的那个组合。那么实际上这个代价最小的这个组合 $\pi^{\star}$。

$$
\pi^{\star}=\underset{\pi \in \Pi(m)}{\arg \min } \sum_{i=1}^{m} \mathcal{C}_{\text {match }}\left(\mathbf{Y}_{i}, \hat{\mathbf{Y}}_{\pi(i)}\right)

$$

其中，这个 $\mathcal{C}_{\text {match }}$ 定义如下，这里是使用的匈牙利算法来计算的，具体的还是参考原论文的附录吧，我看的要不是很明白；如果实在看不懂，跟我一样不管了，这就是为了计算一个代价而已。

$$
\begin{aligned}
\mathcal{C}_{\text {match }}\left(\mathbf{Y}_{i}, \hat{\mathbf{Y}}_{\pi(i)}\right) &=-\mathbb{1}_{\left\{r_{i} \neq \varnothing\right\}}\left[\mathbf{p}_{\pi(i)}^{r}\left(r_{i}\right)\right.\\
&+\mathbf{p}_{\pi(i)}^{s-start}\left(s_{i}^{\text {start }}\right) + \mathbf{p}_{\pi(i)}^{s-end}\left(s_{i}^{end}\right) \\
&+\mathbf{p}_{\pi(i)}^{o-start}\left(o_{i}^{\text {start }}\right)\left . + \mathbf{p}_{\pi(i)}^{o-end}\left(o_{i}^{end}\right)\right]
\end{aligned}

$$

这里注意，上面只是得到了一个代价最小的组合，跟最终的损失还是不一样的，所以还需要针对上面的组合 $\pi^{\star}$ 来计算一下最终的损失。

$$
\begin{aligned}
\mathcal{L}(\mathbf{Y}, \hat{\mathbf{Y}}) &=\sum_{i=1}^{m}\left\{-\log \mathbf{p}_{\pi^{\star}(i)}^{r}\left(r_{i}\right)\right.\\
&+\mathbb{1}_{\left\{r_{i} \neq \varnothing\right\}}\left[-\log \mathbf{p}_{\pi^{\star}(i)}^{s-s t a r t}\left(s_{i}^{\text {start }}\right)\right.\\
&-\log \mathbf{p}_{\pi^{\star}(i)}^{s-e n d}\left(s_{i}^{\text {end }}\right) \\
&-\log \mathbf{p}_{\pi^{\star}(i)}^{o-\text { start }}\left(o_{i}^{\text {start }}\right) \\
&\left.\left.-\log \mathbf{p}_{\pi^{\star}(i)}^{o-e n d}\left(o_{i}^{\text {end }}\right)\right]\right\}
\end{aligned}

$$

然后论文在此戛然而止，就没了，这就是前面所提到的**双联体匹配损失**（bipartite matching loss）我是没看懂。

#### 实验结果

这实验数据还能说啥，到现在还是榜一呢。

![图片](https://xerrors.oss-cn-shanghai.aliyuncs.com/imgs/20210830183405-imagepng)

这是重点看一下这个模型的实验结果有没有能够验证自己的思路和想法，所以首先应该是对比实验；右表是关于解码器和损失函数之间的实验结果；

![图片](https://xerrors.oss-cn-shanghai.aliyuncs.com/imgs/20210830183823-imagepng)

可以看到使用交叉熵损失函数之后效果相对而言，降低了 8.5%；证明了这个损失函数的有效性。不过我觉得这里通过增加解码器层数的方法并不是很有说服力；倒是如下图所示，当 N=1 的时候，此时 Biaprtite Matching Loss 是没有作用的（是的吧），这个非自回归的模型的表现依然是比之前的 SOTA 要好。

![图片](https://xerrors.oss-cn-shanghai.aliyuncs.com/imgs/20210830184512-imagepng)

除此之外，作者还做了一个有趣的实验，如图所示，横着来看， SPN 的 Precision 和 Recall 更加均匀，作者认为是因为在训练的时候自己的 m 的设置的要比句子中的三元组数目要多。

此外，在 WebNLG 里，实体识别和关系提取的结果都比联合提取任务要高，作者认为这意味着实体对抽取和关系类型抽取的准确结合是提高联合实体和关系抽取的关键。

那为啥 NYT 和 WebNLG 有区别呢？区别就是在于 WebNLG 的 SEO 比较多。

![图片](https://xerrors.oss-cn-shanghai.aliyuncs.com/imgs/20210830184823-imagepng)

作者总结：

> 在本文中，我们介绍了用于联合实体和关系提取的集合预测网络。与以往基于seq2seq的模型相比，我们将实体和关系的联合提取任务表述为一个集合预测问题。这样一来，提取模型就可以不必预测多个三元组的提取顺序了。为了解决集合预测问题，我们将非自回归并行解码与双点匹配损失函数相结合。我们在两个广泛使用的数据集上进行了广泛的实验来验证所提出的集合预测网络的有效性。实验结果表明，我们提出的网络在不同场景下的表现优于最先进的基线。这项具有挑战性的任务还远远没有得到解决。我们发现，**关系类型在NYT数据集和WebNLG数据集中表现出不平衡或长尾分布**。我们未来的工作将集中在如何将成本敏感的学习与所提出的集合预测网络相结合。

我的总结：

从作者的实现想法来看，这里的 bipartite matching loss 已经印证了作者的想法；不过我并不清楚是因为和非自回归编码一起使用所导致的。这个值得思考，但作者又没做实验，那就不得而知了。

有一说一，作者在附录里面详细的介绍了匈牙利算法以及 bipartite matching loss 的计算方法。Good！

### 基于异构图神经网络的表征迭代融合

论文在此：[Representation iterative fusion based on heterogeneous graph neural network for joint entity and relation extraction - ScienceDirect](https://www.sciencedirect.com/science/article/pii/S0950705121001519)

有一说一，这名字是真的拗口，读起来很费劲；不过这篇文章是发布在《Knowledge-Based System》，似乎目前是 Sci 一区，不错的。

这篇文章的核心其实就在于增强单词和关系表征之间的联系；我们回忆一下大佬的 CasRel，直接把原始输出经过一个 BERT 之后就算是编码结束了。

![图片](https://xerrors.oss-cn-shanghai.aliyuncs.com/imgs/20210907224518-image.png)

所以这次就把每个单词和每个关系当成节点，使用图神经网络来更新每个节点的特征表示。

话不多说，还是先看摘要：
