---
title: 命名实体识别笔记
date: 2021-07-21 13:02:51
permalink: /ner-beginner-note/
cover: 
tags: 
- 人工智能
- NLP
categories: 人工智能

---

## 1. 命名实体识别 NER

参考资料：

[流水的NLP铁打的NER：命名实体识别实践与探索 - 王岳王院长的文章 - 知乎](https://zhuanlan.zhihu.com/p/166496466)


一篇很好的综述：[[1812.09449] A Survey on Deep Learning for Named Entity Recognition (arxiv.org)](https://arxiv.org/abs/1812.09449)

这是我写的思维导图笔记：[《命名实体识别》](https://shimo.im/mindmaps/3PCHWJCYkw98cgvR/)

![图片](https://xerrors.oss-cn-shanghai.aliyuncs.com/imgs/20210728213903-命名实体识别.jpeg)

NLP四大任务

> 为什么说流水的NLP铁打的NER？NLP四大任务嘛，分类、生成、序列标注、句子对标注。分类任务，面太广了，万物皆可分类，各种方法层出不穷；句子对标注，经常是体现人工智能（zhang）对人类语言理解能力的标准秤，孪生网络、DSSM、ESIM 各种模型一年年也是秀的飞起；生成任务，目前人工智障 NLP 能力的天花板，虽然经常会处在说不出来人话的状态，但也不断吸引 CopyNet、VAE、GAN 各类选手前来挑战；唯有序列标注，数年如一日，不忘初心，原地踏步，到现在一提到 NER，还是会一下子只想到 LSTM-CRF，铁打不动的模型，没得挑也不用挑，用就完事了，不用就是不给面子

ACL2020 做NER的论文主要在做这几个方面：

> 1. 多特征：实体识别不是一个特别复杂的任务，不需要太深入的模型，那么就是加特征，特征越多效果越好，所以字特征、词特征、词性特征、句法特征、KG表征等等的就一个个加吧，甚至有些中文 NER 任务里还加入了拼音特征、笔画特征。。？心有多大，特征就有多多
> 2. 多任务：很多时候做 NER 的目的并不仅是为了 NER，而是服务于一个更大的目标或系统，比如信息抽取、问答系统等等。如果把整个大任务做一个端到端的模型，就需要做成一个多任务模型，把 NER 作为其中一个子任务；另外，单纯的 NER 也可以做成多任务，比如实体类型过多时，仅用一个序列标注任务来同时抽取实体与判断实体类型，会有些力不从心，就可以拆成两个子任务来做.
> 3. 时令大杂烩：把当下比较流行的深度学习话题或方法跟 NER 结合一下，比如结合强化学习的 NER、结合 few-shot learning 的 NER、结合多模态信息的 NER、结合跨语种学习的 NER 等等的，具体就不提了。


## 2. 条件随机场 CRF

上面那篇文章多次提到了CRF，这里就先了解一下什么是CRF。

参考资料：
1. [CRF原理及实现代码 - 微信](https://mp.weixin.qq.com/s/Ql1YGJvH68K8_PIctDsU-Q)

## 3. MECT

MECT: Multi-Metadata Embedding based Cross-Transformer for Chinese Named Entity Recognition（arXiv:2107.05418v1  [cs.CL]  12 Jul 2021）

![图片](https://xerrors.oss-cn-shanghai.aliyuncs.com/imgs/20210721190521-image.png)

主要贡献：

1. 在中文NER使用汉字的多元数据特征嵌入。
2. 提出了一种新的双流模型，该模型结合了汉字的部首、字符和单词，提高了所提方法的性能。
3. 在几个著名的中文NER基准数据集上对所提出的方法进行了评估，证明了所提出的方法优于最先进的方法。


![图片](https://xerrors.oss-cn-shanghai.aliyuncs.com/imgs/20210721190840-image.png)

